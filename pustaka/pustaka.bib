
@misc{hu_multi-scale_2023,
	title = {Multi-scale {Multi}-site {Renal} {Microvascular} {Structures} {Segmentation} for {Whole} {Slide} {Imaging} in {Renal} {Pathology}},
	url = {http://arxiv.org/abs/2308.05782},
	abstract = {Segmentation of microvascular structures, such as arterioles, venules, and capillaries, from human kidney whole slide images (WSI) has become a focal point in renal pathology. Current manual segmentation techniques are time-consuming and not feasible for large-scale digital pathology images. While deep learning-based methods offer a solution for automatic segmentation, most suffer from a limitation: they are designed for and restricted to training on single-site, single-scale data. In this paper, we present Omni-Seg, a novel single dynamic network method that capitalizes on multi-site, multiscale training data. Unique to our approach, we utilize partially labeled images, where only one tissue type is labeled per training image, to segment microvascular structures. We train a singular deep network using images from two datasets, HuBMAP and NEPTUNE, across different magnifications (40×, 20×, 10×, and 5×). Experimental results indicate that Omni-Seg outperforms in terms of both the Dice Similarity Coefficient (DSC) and Intersection over Union (IoU). Our proposed method provides renal pathologists with a powerful computational tool for the quantitative analysis of renal microvascular structures.},
	language = {en},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Hu, Franklin and Deng, Ruining and Bao, Shunxing and Yang, Haichun and Huo, Yuankai},
	month = aug,
	year = {2023},
	note = {arXiv:2308.05782 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Hu et al. - 2023 - Multi-scale Multi-site Renal Microvascular Structu.pdf:C\:\\Users\\junpi\\Zotero\\storage\\LG2AQYZJ\\Hu et al. - 2023 - Multi-scale Multi-site Renal Microvascular Structu.pdf:application/pdf},
}

@article{jain_advances_2023,
	title = {Advances and prospects for the {Human} {BioMolecular} {Atlas} {Program} ({HuBMAP})},
	volume = {25},
	issn = {1465-7392, 1476-4679},
	url = {https://www.nature.com/articles/s41556-023-01194-w},
	doi = {10.1038/s41556-023-01194-w},
	language = {en},
	number = {8},
	urldate = {2024-04-27},
	journal = {Nature Cell Biology},
	author = {Jain, Sanjay and Pei, Liming and Spraggins, Jeffrey M. and Angelo, Michael and Carson, James P. and Gehlenborg, Nils and Ginty, Fiona and Gonçalves, Joana P. and Hagood, James S. and Hickey, John W. and Kelleher, Neil L. and Laurent, Louise C. and Lin, Shin and Lin, Yiing and Liu, Huiping and Naba, Alexandra and Nakayasu, Ernesto S. and Qian, Wei-Jun and Radtke, Andrea and Robson, Paul and Stockwell, Brent R. and Van De Plas, Raf and Vlachos, Ioannis S. and Zhou, Mowei and {HuBMAP Consortium} and Ahn, Kyung Jin and Allen, Jamie and Anderson, David M. and Anderton, Christopher R. and Curcio, Christine and Angelin, Alessia and Arvanitis, Constadina and Atta, Lyla and Awosika-Olumo, Demi and Bahmani, Amir and Bai, Huajun and Balderrama, Karol and Balzano, Leandro and Bandyopadhyay, Gautam and Bandyopadhyay, Shovik and Bar-Joseph, Ziv and Barnhart, Kurt and Barwinska, Daria and Becich, Michael and Becker, Laren and Becker, Winston and Bedi, Kenneth and Bendall, Sean and Benninger, Kathy and Betancur, David and Bettinger, Keith and Billings, Sunteasja and Blood, Philip and Bolin, Daniel and Border, Samuel and Bosse, Marc and Bramer, Lisa and Brewer, Maya and Brusko, Maigan and Bueckle, Andreas and Burke, Karl and Burnum-Johnson, Kristin and Butcher, Eugene and Butterworth, Elizabeth and Cai, Long and Calandrelli, Riccardo and Caldwell, Michael and Campbell-Thompson, Martha and Cao, Dongfeng and Cao-Berg, Ivan and Caprioli, Richard and Caraccio, Chiara and Caron, Anita and Carroll, Megan and Chadwick, Chrystal and Chen, Angela and Chen, Derek and Chen, Fei and Chen, Haoran and Chen, Jing and Chen, Li and Chen, Lu and Chiacchia, Kenneth and Cho, Sanghee and Chou, Peter and Choy, Lisa and Cisar, Cecilia and Clair, Geremy and Clarke, Laura and Clouthier, Kelly A. and Colley, Madeline E. and Conlon, Kristin and Conroy, John and Contrepois, Kevin and Corbett, Anthony and Corwin, Alex and Cotter, Daniel and Courtois, Elise and Cruz, Aaron and Csonka, Christopher and Czupil, Kimberley and Daiya, Vicky and Dale, Kali and Davanagere, Shakeel Ahamed and Dayao, Monica and De Caestecker, Mark P. and Decker, Aubrianna and Deems, Stephen and Degnan, David and Desai, Tushar and Deshpande, Vikrant and Deutsch, Gail and Devlin, Michelle and Diep, Dinh and Dodd, Carla and Donahue, Sean and Dong, Weixiu and Dos Santos Peixoto, Rafael and Duffy, Michael and Dufresne, Martin and Duong, Thu Elizabeth and Dutra, Jennifer and Eadon, Michael T. and El-Achkar, Tarek M. and Enninful, Archibald and Eraslan, Gokcen and Eshelman, Diane and Espin-Perez, Almudena and Esplin, Edward D. and Esselman, Allison and Falo, Louis D. and Falo, Louis and Fan, Jean and Fan, Rong and Farrow, Melissa A. and Farzad, Negin and Favaro, Patricia and Fermin, Jamie and Filiz, Ferda and Filus, Shane and Fisch, Kathleen and Fisher, Eyal and Fisher, Stephen and Flowers, Katelyn and Flynn, William F. and Fogo, Agnes B. and Fu, Dongtao and Fulcher, James and Fung, Anthony and Furst, Derek and Gallant, Michael and Gao, Fu and Gao, Yu and Gaulton, Kyle and Gaut, Joseph P. and Gee, James and Ghag, Reetika R. and Ghazanfar, Shila and Ghose, Soumya and Gisch, Debora and Gold, Ilan and Gondalia, Aashay and Gorman, Brittney and Greenleaf, William and Greenwald, Noah and Gregory, Brian and Guo, Rong and Gupta, Rajat and Hakimian, Hunter and Haltom, Jeff and Halushka, Marc and Han, Kyu Sang and Hanson, Casey and Harbury, Pehr and Hardi, Josef and Harlan, Linda and Harris, Raymond C. and Hartman, Austin and Heidari, Elyas and Helfer, Jesse and Helminiak, David and Hemberg, Martin and Henning, Nathaniel and Herr, Bruce W. and Ho, Jonhan and Holden-Wiltse, Jeanne and Hong, Seung-Hyun and Hong, Young-Kwon and Honick, Brendan and Hood, Greg and Hu, Po and Hu, Qiwen and Huang, Molly and Huyck, Heidie and Imtiaz, Tamjid and Isberg, Olof Gerdur and Itkin, Maxim and Jackson, Dana and Jacobs, Marni and Jain, Yashvardhan and Jewell, David and Jiang, Lihua and Jiang, Zhenghui G. and Johnston, Sarah and Joshi, Pujan and Ju, Yingnan and Judd, Audra and Kagel, Adam and Kahn, Ari and Kalavros, Nikolaos and Kalhor, Kian and Karagkouni, Dimitra and Karathanos, Thomas and Karunamurthy, Arivarasan and Katari, Suhas and Kates, Heather and Kaushal, Madhurima and Keener, Nicholas and Keller, Mark and Kenney, Mariah and Kern, Colin and Kharchenko, Peter and Kim, Junhyong and Kingsford, Carl and Kirwan, Jessica and Kiselev, Vladimir and Kishi, Jocelyn and Kitata, Reta Birhanu and Knoten, Amanda and Kollar, Charles and Krishnamoorthy, Praveen and Kruse, Angela R. S. and Da, Kuang and Kundaje, Anshul and Kutschera, Eric and Kwon, Yumi and Lake, Blue B. and Lancaster, Samuel and Langlieb, Jonah and Lardenoije, Roy and Laronda, Monica and Laskin, Julia and Lau, Ken and Lee, Hayan and Lee, Maria and Lee, Mejeong and Strekalova, Yulia Levites and Li, Dongshunyi and Li, Jennifer and Li, Jilong and Li, Xiangtang and Li, Zhi and Liao, Yen-Chen and Liaw, Tiffany and Lin, Pei and Lin, Yulieh and Lindsay, Scott and Liu, Chunjie and Liu, Yang and Liu, Yuan and Lott, Marie and Lotz, Martin and Lowery, Lisa and Lu, Peiran and Lu, Xinyue and Lucarelli, Nicholas and Lun, Xiaokang and Luo, Zhifei and Ma, Jian and Macosko, Evan and Mahajan, Mayank and Maier, Libby and Makowski, Danika and Malek, Morad and Manthey, David and Manz, Trevor and Margulies, Kenneth and Marioni, John and Martindale, Matthew and Mason, Cayla and Mathews, Clayton and Maye, Peter and McCallum, Chuck and McDonough, Elizabeth and McDonough, Liz and Mcdowell, Hannah and Meads, Morgan and Medina-Serpas, Miguel and Ferreira, Ricardo Melo and Messinger, Jeffrey and Metis, Kay and Migas, Lukasz G. and Miller, Brendan and Mimar, Sayat and Minor, Brittany and Misra, Ravi and Missarova, Alsu and Mistretta, Christopher and Moens, Roger and Moerth, Eric and Moffitt, Jeffrey and Molla, Gesmira and Monroe, Matthew and Monte, Emma and Morgan, Mike and Muraro, Daniele and Murphy, Bob and Murray, Evan and Musen, Mark A. and Naglah, Ahmed and Nasamran, Chanond and Neelakantan, Taruna and Nevins, Stephanie and Nguyen, Hieu and Nguyen, Nam and Nguyen, Tram and Nguyen, Tri and Nigra, Deb and Nofal, Michel and Nolan, Garry and Nwanne, Gerald and O’Connor, Martin and Okuda, Kenichi and Olmer, Merissa and O’Neill, Kathleen and Otaluka, Nancy and Pang, Minxing and Parast, Mana and Pasa-Tolic, Ljiljana and Paten, Benedict and Patterson, Nathan Heath and Peng, Ting and Phillips, Gesina and Pichavant, Mina and Piehowski, Paul and Pilner, Hannah and Pingry, Ellie and Pita-Juarez, Yered and Plevritis, Sylvia and Ploumakis, Athanasios and Pouch, Alison and Pryhuber, Gloria and Puerto, Juan and Qaurooni, Danial and Qin, Ling and Quardokus, Ellen M. and Rajbhandari, Presha and Rakow-Penner, Rebecca and Ramasamy, Ramalakshmi and Read, David and Record, Elizabeth G. and Reeves, David and Ricarte, Allyson and Rodríguez-Soto, Ana and Ropelewski, Alexander and Rosario, Jean and Roselkis, Morla-Adames and Rowe, David and Roy, Tarun Kanti and Ruffalo, Matt and Ruschman, Nancy and Sabo, Angela and Sachdev, Nina and Saka, Sinem and Salamon, Diane and Sarder, Pinaki and Sasaki, Hiroshi and Satija, Rahul and Saunders, Diane and Sawka, Riley and Schey, Kevin and Schlehlein, Heidi and Scholten, David and Schultz, Sarah and Schwartz, Lauren and Schwenk, Melissa and Scibek, Robin and Segre, Ayellet and Serrata, Matthew and Shands, Walter and Shen, Xiaotao and Shendure, Jay and Shephard, Holly and Shi, Lingyan and Shi, Tujin and Shin, Dong-Guk and Shirey, Bill and Sibilla, Max and Silber, Michal and Silverstein, Jonathan and Simmel, Derek and Simmons, Alan and Singhal, Dhruv and Sivajothi, Santhosh and Smits, Thomas and Soncin, Francesca and Song, Qi and Stanley, Valentina and Stuart, Tim and Su, Hanquan and Su, Pei and Sun, Xin and Surrette, Christine and Swahn, Hannah and Tan, Kai and Teichmann, Sarah and Tejomay, Abhiroop and Tellides, George and Thomas, Kathleen and Thomas, Tracey and Thompson, Marissa and Tian, Hua and Tideman, Leonoor and Trapnell, Cole and Tsai, Albert G. and Tsai, Chia-Feng and Tsai, Leo and Tsui, Elizabeth and Tsui, Tina and Tung, Jason and Turner, Morgan and Uranic, Jackie and Vaishnav, Eeshit Dhaval and Varra, Sricharan Reddy and Vaskivskyi, Vasyl and Velickovic, Dusan and Velickovic, Marija and Verheyden, Jamie and Waldrip, Jessica and Wallace, Douglas and Wan, Xueyi and Wang, Allen and Wang, Fusheng and Wang, Meng and Wang, Shuoshuo and Wang, Xuefei and Wasserfall, Clive and Wayne, Leonard and Webber, James and Weber, Griffin M. and Wei, Bei and Wei, Jian-Jun and Weimer, Annika and Welling, Joel and Wen, Xingzhao and Wen, Zishen and Williams, MacKenzie and Winfree, Seth and Winograd, Nicholas and Woodard, Abashai and Wright, Devin and Wu, Fan and Wu, Pei-Hsun and Wu, Qiuyang and Wu, Xiaodong and Xing, Yi and Xu, Tianyang and Yang, Manxi and Yang, Mingyu and Yap, Joseph and Ye, Dong Hye and Yin, Peng and Yuan, Zhou and Yun, Chi and Zahraei, Ali and Zemaitis, Kevin and Zhang, Bo and Zhang, Caibin and Zhang, Chenyu and Zhang, Chi and Zhang, Kun and Zhang, Shiping and Zhang, Ted and Zhang, Yida and Zhao, Bingqing and Zhao, Wenxin and Zheng, Jia Wen and Zhong, Sheng and Zhu, Bokai and Zhu, Chenchen and Zhu, Diming and Zhu, Quan and Zhu, Ying and Börner, Katy and Snyder, Michael P.},
	month = aug,
	year = {2023},
	pages = {1089--1100},
	file = {Jain et al. - 2023 - Advances and prospects for the Human BioMolecular .pdf:C\:\\Users\\junpi\\Zotero\\storage\\8X3MUM8C\\Jain et al. - 2023 - Advances and prospects for the Human BioMolecular .pdf:application/pdf},
}

@article{lake_atlas_2023,
	title = {An atlas of healthy and injured cell states and niches in the human kidney},
	volume = {619},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-023-05769-3},
	doi = {10.1038/s41586-023-05769-3},
	abstract = {Abstract
            
              Understanding kidney disease relies on defining the complexity of cell types and states, their associated molecular profiles and interactions within tissue neighbourhoods
              1
              . Here we applied multiple single-cell and single-nucleus assays ({\textgreater}400,000 nuclei or cells) and spatial imaging technologies to a broad spectrum of healthy reference kidneys (45 donors) and diseased kidneys (48 patients). This has provided a high-resolution cellular atlas of 51 main cell types, which include rare and previously undescribed cell populations. The multi-omic approach provides detailed transcriptomic profiles, regulatory factors and spatial localizations spanning the entire kidney. We also define 28 cellular states across nephron segments and interstitium that were altered in kidney injury, encompassing cycling, adaptive (successful or maladaptive repair), transitioning and degenerative states. Molecular signatures permitted the localization of these states within injury neighbourhoods using spatial transcriptomics, while large-scale 3D imaging analysis (around 1.2 million neighbourhoods) provided corresponding linkages to active immune responses. These analyses defined biological pathways that are relevant to injury time-course and niches, including signatures underlying epithelial repair that predicted maladaptive states associated with a decline in kidney function. This integrated multimodal spatial cell atlas of healthy and diseased human kidneys represents a comprehensive benchmark of cellular states, neighbourhoods, outcome-associated signatures and publicly available interactive visualizations.},
	language = {en},
	number = {7970},
	urldate = {2024-04-27},
	journal = {Nature},
	author = {Lake, Blue B. and Menon, Rajasree and Winfree, Seth and Hu, Qiwen and Melo Ferreira, Ricardo and Kalhor, Kian and Barwinska, Daria and Otto, Edgar A. and Ferkowicz, Michael and Diep, Dinh and Plongthongkum, Nongluk and Knoten, Amanda and Urata, Sarah and Mariani, Laura H. and Naik, Abhijit S. and Eddy, Sean and Zhang, Bo and Wu, Yan and Salamon, Diane and Williams, James C. and Wang, Xin and Balderrama, Karol S. and Hoover, Paul J. and Murray, Evan and Marshall, Jamie L. and Noel, Teia and Vijayan, Anitha and Hartman, Austin and Chen, Fei and Waikar, Sushrut S. and Rosas, Sylvia E. and Wilson, Francis P. and Palevsky, Paul M. and Kiryluk, Krzysztof and Sedor, John R. and Toto, Robert D. and Parikh, Chirag R. and Kim, Eric H. and Satija, Rahul and Greka, Anna and Macosko, Evan Z. and Kharchenko, Peter V. and Gaut, Joseph P. and Hodgin, Jeffrey B. and {KPMP Consortium} and Knight, Richard and Lecker, Stewart H. and Stillman, Isaac and Amodu, Afolarin A. and Ilori, Titlayo and Maikhor, Shana and Schmidt, Insa and McMahon, Gearoid M. and Weins, Astrid and Hacohen, Nir and Bush, Lakeshia and Gonzalez-Vicente, Agustin and Taliercio, Jonathan and O’toole, John and Poggio, Emilio and Cooperman, Leslie and Jolly, Stacey and Herlitz, Leal and Nguyen, Jane and Palmer, Ellen and Sendrey, Dianna and Spates-Harden, Kassandra and Appelbaum, Paul and Barasch, Jonathan M. and Bomback, Andrew S. and D’Agati, Vivette D. and Mehl, Karla and Canetta, Pietro A. and Shang, Ning and Balderes, Olivia and Kudose, Satoru and Barisoni, Laura and Alexandrov, Theodore and Cheng, Yinghua and Dunn, Kenneth W. and Kelly, Katherine J. and Sutton, Timothy A. and Wen, Yumeng and Corona-Villalobos, Celia P. and Menez, Steven and Rosenberg, Avi and Atta, Mohammed and Johansen, Camille and Sun, Jennifer and Roy, Neil and Williams, Mark and Azeloglu, Evren U. and He, Cijang and Iyengar, Ravi and Hansen, Jens and Xiong, Yuguang and Rovin, Brad and Parikh, Samir and Madhavan, Sethu M. and Anderton, Christopher R. and Pasa-Tolic, Ljiljana and Velickovic, Dusan and Troyanskaya, Olga and Sealfon, Rachel and Tuttle, Katherine R. and Laszik, Zoltan G. and Nolan, Garry and Sarwal, Minnie and Anjani, Kavya and Sigdel, Tara and Ascani, Heather and Balis, Ulysses G. J. and Lienczewski, Chrysta and Steck, Becky and He, Yougqun and Schaub, Jennifer and Blanc, Victoria M. and Murugan, Raghavan and Randhawa, Parmjeet and Rosengart, Matthew and Tublin, Mitchell and Vita, Tina and Kellum, John A. and Hall, Daniel E. and Elder, Michele M. and Winters, James and Gilliam, Matthew and Alpers, Charles E. and Blank, Kristina N. and Carson, Jonas and De Boer, Ian H. and Dighe, Ashveena L. and Himmelfarb, Jonathan and Mooney, Sean D. and Shankland, Stuart and Williams, Kayleen and Park, Christopher and Dowd, Frederick and McClelland, Robyn L. and Daniel, Stephen and Hoofnagle, Andrew N. and Wilcox, Adam and Bansal, Shweta and Sharma, Kumar and Venkatachalam, Manjeri and Zhang, Guanshi and Pamreddy, Annapurna and Kakade, Vijaykumar R. and Moledina, Dennis and Shaw, Melissa M. and Ugwuowo, Ugochukwu and Arora, Tanima and Ardayfio, Joseph and Bebiak, Jack and Brown, Keith and Campbell, Catherine E. and Saul, John and Shpigel, Anna and Stutzke, Christy and Koewler, Robert and Campbell, Taneisha and Hayashi, Lynda and Jefferson, Nichole and Pinkeney, Roy and Roberts, Glenda V. and Eadon, Michael T. and Dagher, Pierre C. and El-Achkar, Tarek M. and Zhang, Kun and Kretzler, Matthias and Jain, Sanjay},
	month = jul,
	year = {2023},
	pages = {585--594},
	file = {Lake et al. - 2023 - An atlas of healthy and injured cell states and ni.pdf:C\:\\Users\\junpi\\Zotero\\storage\\6QB95W35\\Lake et al. - 2023 - An atlas of healthy and injured cell states and ni.pdf:application/pdf},
}

@article{weber_considerations_2020,
	title = {Considerations for {Using} the {Vasculature} as a {Coordinate} {System} to {Map} {All} the {Cells} in the {Human} {Body}},
	volume = {7},
	issn = {2297-055X},
	url = {https://www.frontiersin.org/article/10.3389/fcvm.2020.00029/full},
	doi = {10.3389/fcvm.2020.00029},
	abstract = {Several ongoing international efforts are developing methods of localizing single cells within organs or mapping the entire human body at the single cell level, including the Chan Zuckerberg Initiative’s Human Cell Atlas (HCA), and the Knut and Allice Wallenberg Foundation’s Human Protein Atlas (HPA), and the National Institutes of Health’s Human BioMolecular Atlas Program (HuBMAP). Their goals are to understand cell specialization, interactions, spatial organization in their natural context, and ultimately the function of every cell within the body. In the same way that the Human Genome Project had to assemble sequence data from different people to construct a complete sequence, multiple centers around the world are collecting tissue specimens from diverse populations that vary in age, race, sex, and body size. A challenge will be combining these heterogeneous tissue samples into a 3D reference map that will enable multiscale, multidimensional Google Maps-like exploration of the human body. Key to making alignment of tissue samples work is identifying and using a coordinate system called a Common Coordinate Framework (CCF), which deﬁnes the positions, or “addresses,” in a reference body, from whole organs down to functional tissue units and individual cells. In this perspective, we examine the concept of a CCF based on the vasculature and describe why it would be an attractive choice for mapping the human body.},
	language = {en},
	urldate = {2024-04-29},
	journal = {Frontiers in Cardiovascular Medicine},
	author = {Weber, Griffin M. and Ju, Yingnan and Börner, Katy},
	month = mar,
	year = {2020},
	pages = {29},
	file = {Weber et al. - 2020 - Considerations for Using the Vasculature as a Coor.pdf:C\:\\Users\\junpi\\Zotero\\storage\\EML594K7\\Weber et al. - 2020 - Considerations for Using the Vasculature as a Coor.pdf:application/pdf},
}

@incollection{galis_vasculome_2022,
	title = {The {Vasculome} provides a body-wide cellular positioning system and functional barometer. {The} “{Vasculature} as {Common} {Coordinate} {Frame} ({VCCF})” concept},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-822546-2},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B978012822546200037X},
	language = {en},
	urldate = {2024-05-03},
	booktitle = {The {Vasculome}},
	publisher = {Elsevier},
	author = {Galis, Zorina S.},
	year = {2022},
	doi = {10.1016/B978-0-12-822546-2.00037-X},
	pages = {453--460},
}

@article{huang_fully_2022,
	title = {Fully {Convolutional} {Network} for the {Semantic} {Segmentation} of {Medical} {Images}: {A} {Survey}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2075-4418},
	shorttitle = {Fully {Convolutional} {Network} for the {Semantic} {Segmentation} of {Medical} {Images}},
	url = {https://www.mdpi.com/2075-4418/12/11/2765},
	doi = {10.3390/diagnostics12112765},
	abstract = {There have been major developments in deep learning in computer vision since the 2010s. Deep learning has contributed to a wealth of data in medical image processing, and semantic segmentation is a salient technique in this ﬁeld. This study retrospectively reviews recent studies on the application of deep learning for segmentation tasks in medical imaging and proposes potential directions for future development, including model development, data augmentation processing, and dataset creation. The strengths and deﬁciencies of studies on models and data augmentation, as well as their application to medical image segmentation, were analyzed. Fully convolutional network developments have led to the creation of the U-Net and its derivatives. Another noteworthy image segmentation model is DeepLab. Regarding data augmentation, due to the low data volume of medical images, most studies focus on means to increase the wealth of medical image data. Generative adversarial networks (GAN) increase data volume via deep learning. Despite the increasing types of medical image datasets, there is still a deﬁciency of datasets on speciﬁc problems, which should be improved moving forward. Considering the wealth of ongoing research on the application of deep learning processing to medical image segmentation, the data volume and practical clinical application problems must be addressed to ensure that the results are properly applied.},
	language = {en},
	number = {11},
	urldate = {2024-05-03},
	journal = {Diagnostics},
	author = {Huang, Sheng-Yao and Hsu, Wen-Lin and Hsu, Ren-Jun and Liu, Dai-Wei},
	month = nov,
	year = {2022},
	pages = {2765},
	file = {Huang et al. - 2022 - Fully Convolutional Network for the Semantic Segme.pdf:C\:\\Users\\junpi\\Zotero\\storage\\8YI2WFFC\\Huang et al. - 2022 - Fully Convolutional Network for the Semantic Segme.pdf:application/pdf},
}

@inproceedings{cootes_statistical_2001,
	address = {San Diego, CA},
	title = {Statistical models of appearance for medical image analysis and computer vision},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=906296},
	doi = {10.1117/12.431093},
	urldate = {2024-05-06},
	author = {Cootes, Tim F. and Taylor, Christopher J.},
	editor = {Sonka, Milan and Hanson, Kenneth M.},
	month = jul,
	year = {2001},
	pages = {236--248},
	file = {236.pdf:C\:\\Users\\junpi\\Zotero\\storage\\JS5JE3W8\\236.pdf:application/pdf},
}

@misc{cai_ma-unet_2020,
	title = {{MA}-{Unet}: {An} improved version of {Unet} based on multi-scale and attention mechanism for medical image segmentation},
	shorttitle = {{MA}-{Unet}},
	url = {http://arxiv.org/abs/2012.10952},
	abstract = {Although convolutional neural networks (CNNs) are promoting the development of medical image semantic segmentation, the standard model still has some shortcomings. First, the feature mapping from the encoder and decoder sub-networks in the skip connection operation has a large semantic diﬀerence. Second, the remote feature dependence is not eﬀectively modeled. Third, the global context information of diﬀerent scales is ignored. In this paper, we try to eliminate semantic ambiguity in skip connection operations by adding attention gates (AGs), and use attention mechanisms to combine local features with their corresponding global dependencies, explicitly model the dependencies between channels and use multiscale predictive fusion to utilize global information at diﬀerent scales. Compared with other state-of-theart segmentation networks, our model obtains better segmentation performance while introducing fewer parameters.},
	language = {en},
	urldate = {2024-05-07},
	publisher = {arXiv},
	author = {Cai, Yutong and Wang, Yong},
	month = dec,
	year = {2020},
	note = {arXiv:2012.10952 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Cai and Wang - 2020 - MA-Unet An improved version of Unet based on mult.pdf:C\:\\Users\\junpi\\Zotero\\storage\\HF34SGMS\\Cai and Wang - 2020 - MA-Unet An improved version of Unet based on mult.pdf:application/pdf},
}

@article{yousefi_esophageal_2021,
	title = {Esophageal {Tumor} {Segmentation} in {CT} {Images} {Using} a {Dilated} {Dense} {Attention} {Unet} ({DDAUnet})},
	volume = {9},
	abstract = {Manual or automatic delineation of the esophageal tumor in CT images is known to be very challenging. This is due to the low contrast between the tumor and adjacent tissues, the anatomical variation of the esophagus, as well as the occasional presence of foreign bodies (e.g. feeding tubes). Physicians therefore usually exploit additional knowledge such as endoscopic ﬁndings, clinical history, additional imaging modalities like PET scans. Achieving his additional information is time-consuming, while the results are error-prone and might lead to non-deterministic results. In this paper we aim to investigate if and to what extent a simpliﬁed clinical workﬂow based on CT alone, allows one to automatically segment the esophageal tumor with sufﬁcient quality. For this purpose, we present a fully automatic end-to-end esophageal tumor segmentation method based on convolutional neural networks (CNNs). The proposed network, called Dilated Dense Attention Unet (DDAUnet), leverages spatial and channel attention gates in each dense block to selectively concentrate on determinant feature maps and regions. Dilated convolutional layers are used to manage GPU memory and increase the network receptive ﬁeld. We collected a dataset of 792 scans from 288 distinct patients including varying anatomies with air pockets, feeding tubes and proximal tumors. Repeatability and reproducibility studies were conducted for three distinct splits of training and validation sets. The proposed network achieved a DSC value of 0.79 ± 0.20, a mean surface distance of 5.4 ± 20.2mm and 95\% Hausdorff distance of 14.7 ± 25.0mm for 287 test scans, demonstrating promising results with a simpliﬁed clinical workﬂow based on CT alone. Our code is publicly available via https://github.com/yousefis/DenseUnet\_Esophagus\_Segmentation.},
	language = {en},
	author = {Yousefi, Sahar and Sokooti, Hessam and Elmahdy, Mohamed S and Lips, Irene M and Shalmani, Mohammad T Manzuri and Zinkstok, Roel T},
	year = {2021},
	file = {Yousefi et al. - 2021 - Esophageal Tumor Segmentation in CT Images Using a.pdf:C\:\\Users\\junpi\\Zotero\\storage\\MVTQ7XHH\\Yousefi et al. - 2021 - Esophageal Tumor Segmentation in CT Images Using a.pdf:application/pdf},
}

@misc{noor_survey_2024,
	title = {A {Survey} on {Deep} {Learning} and {State}-of-the-art {Applications}},
	url = {http://arxiv.org/abs/2403.17561},
	abstract = {Deep learning, a branch of artificial intelligence, is a computational model that uses multiple layers of interconnected units (neurons) to learn intricate patterns and representations directly from raw input data. Empowered by this learning capability, it has become a powerful tool for solving complex problems and is the core driver of many groundbreaking technologies and innovations. Building a deep learning model is a challenging task due to the algorithm’s complexity and the dynamic nature of real-world problems. Several studies have reviewed deep learning concepts and applications. However, the studies mostly focused on the types of deep learning models and convolutional neural network architectures, offering limited coverage of the state-of-the-art of deep learning models and their applications in solving complex problems across different domains. Therefore, motivated by the limitations, this study aims to comprehensively review the state-of-the-art deep learning models in computer vision, natural language processing, time series analysis and pervasive computing. We highlight the key features of the models and their effectiveness in solving the problems within each domain. Furthermore, this study presents the fundamentals of deep learning, various deep learning model types and prominent convolutional neural network architectures. Finally, challenges and future directions in deep learning research are discussed to offer a broader perspective for future researchers.},
	language = {en},
	urldate = {2024-05-08},
	publisher = {arXiv},
	author = {Noor, Mohd Halim Mohd and Ige, Ayokunle Olalekan},
	month = mar,
	year = {2024},
	note = {arXiv:2403.17561 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Noor and Ige - 2024 - A Survey on Deep Learning and State-of-the-art App.pdf:C\:\\Users\\junpi\\Zotero\\storage\\8ZITPZJB\\Noor and Ige - 2024 - A Survey on Deep Learning and State-of-the-art App.pdf:application/pdf},
}

@misc{deng_omni-seg_2022,
	title = {Omni-{Seg}: {A} {Single} {Dynamic} {Network} for {Multi}-label {Renal} {Pathology} {Image} {Segmentation} using {Partially} {Labeled} {Data}},
	shorttitle = {Omni-{Seg}},
	url = {http://arxiv.org/abs/2112.12665},
	abstract = {Computer-assisted quantitative analysis on Giga-pixel pathology images has provided a new avenue in histology examination. The innovations have been largely focused on cancer pathology (i.e., tumor segmentation and characterization). In non-cancer pathology, the learning algorithms can be asked to examine more comprehensive tissue types simultaneously, as a multi-label setting. The prior arts typically needed to train multiple segmentation networks in order to match the domain-speciﬁc knowledge for heterogeneous tissue types (e.g., glomerular tuft, glomerular unit, proximal tubular, distal tubular, peritubular capillaries, and arteries). In this paper, we propose a dynamic single segmentation network (Omni-Seg) that learns to segment multiple tissue types using partially labeled images (i.e., only one tissue type is labeled for each training image) for renal pathology. By learning from 150,000 patch-wise pathological images from six tissue types, the proposed Omni-Seg network achieved superior segmentation accuracy and less resource consumption when compared to the previous the multiple-network and multi-head design. In the testing stage, the proposed method obtains “completely labeled” tissue segmentation results using only “partially labeled” training images. The source code is available at https://github.com/ddrrnn123/Omni-Seg.},
	language = {en},
	urldate = {2024-05-08},
	publisher = {arXiv},
	author = {Deng, Ruining and Liu, Quan and Cui, Can and Asad, Zuhayr and Yang, Haichun and Huo, Yuankai},
	month = mar,
	year = {2022},
	note = {arXiv:2112.12665 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Deng et al. - 2022 - Omni-Seg A Single Dynamic Network for Multi-label.pdf:C\:\\Users\\junpi\\Zotero\\storage\\UG9ZDKTA\\Deng et al. - 2022 - Omni-Seg A Single Dynamic Network for Multi-label.pdf:application/pdf},
}

@book{mescher_junqueiras_2021,
	address = {New York},
	edition = {Sixteenth edition},
	title = {Junqueira's basic histology: text and atlas},
	isbn = {978-1-260-46297-5},
	shorttitle = {Junqueira's basic histology},
	abstract = {"For five decades this educational resource has met the needs of learners for a well-organized and summarizing presentation of cell biology and histology that integrates the material with that of biochemistry, immunology, endocrinology, and physiology and provides an excellent foundation for subsequent studies in pathology. The text is prepared specifically for students of medicine and other health-related professions, as well as for advanced undergraduate courses in human tissue biology"--Preface},
	language = {en},
	publisher = {McGraw-Hill},
	author = {Mescher, Anthony L. and Junqueira, Luiz Carlos Uchôa},
	year = {2021},
	note = {OCLC: 1245858407},
	file = {Mescher and Junqueira - 2021 - Junqueira's basic histology text and atlas.pdf:C\:\\Users\\junpi\\Zotero\\storage\\8R4W4K9G\\Mescher and Junqueira - 2021 - Junqueira's basic histology text and atlas.pdf:application/pdf},
}

@article{ito_s-27-1_2023,
	title = {S-27-1: {THE} {ROLE} {OF} {KIDNEY} {IN} {BLOOD} {PRESSURE} {REGULATION}},
	volume = {41},
	issn = {0263-6352, 1473-5598},
	shorttitle = {S-27-1},
	url = {https://journals.lww.com/10.1097/01.hjh.0000913320.72966.c9},
	doi = {10.1097/01.hjh.0000913320.72966.c9},
	abstract = {The kidney plays important roles in homeostasis of body fluid and electrolyte balances as well as blood pressure (BP) regulation. For these, two functions are required. One is a stable and huge (150L/day) amount of glomerular filtration rate (GFR) in the face of large variations of BP and dairy salt intake, and the other is pressure natriuresis. Even if BP changed acutely, glomerular capillary pressure of each nephron is maintained relatively stale by myogenic response and tubuloglomerular feedback (TGF). When salt intake is changed, GFR is maintained by exquisitely precise and elegant interplays among the rein-angiotensin-aldosterone (RAA) system, TGF and connecting TGF (cTGF). The cTGF is a recently discovered intrinsic mechanism controlling glomerular hemodynamics. The pressure natriuresis plays a crucial role in the maintenance of body fluid volume, and its site of action is renal medulla. Blood supply to renal medulla is governed by descending vasa recta, the efferent arteriole of the juxtaglomerulus. In outer medulla, thick ascending limb of juxtamedullary nephron makes direct contact with descending vasa recta. Studies indicate that nitric oxide and oxidative stress produced by this tubular segment affect vascular tone of descending vasa recta, a phenomenon called tubulo-vascular crosstalk. The tubule-vascular crosstalk is implicated to play an important role in oxygen metabolism in such conditions as heart failure and high salt intake. In this presentation, I will discuss above mentioned mechanisms that control renal hemodynamics, sodium balances and BP.},
	language = {en},
	number = {Suppl 1},
	urldate = {2024-05-14},
	journal = {Journal of Hypertension},
	author = {Ito, Sadayoshi},
	month = jan,
	year = {2023},
	pages = {e62},
}

@incollection{bagarao_renal_2023,
	title = {Renal {Physiology} {Theory} and {Functional} {Assessment}},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-323-95884-4},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780323958844000093},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Biomedical {Engineering} of {Pancreatic}, {Pulmonary}, and {Renal} {Systems}, and {Applications} to {Medicine}},
	publisher = {Elsevier},
	author = {BagaRao, Sudhir and Ghista, Dhanjoo N.},
	year = {2023},
	doi = {10.1016/B978-0-323-95884-4.00009-3},
	pages = {543--572},
}

@book{abdulla_biology_2022,
	address = {Place of publication not identified},
	edition = {First edition},
	title = {The biology of ageing and its clinical implication: a practical handbook},
	isbn = {978-1-84619-792-5},
	shorttitle = {The biology of ageing and its clinical implication},
	abstract = {"The Biology of Ageing provides the reader with: a learning guide on the biology of ageing through an overview of the changes that occur at both cellular and system levels; knowledge of how biological changes of ageing impact on physiology and the clinical relevance in medical practice; and a practical consideration of these changes in disease presentations and how these changes may impact on disease management." [back cover]},
	language = {eng},
	publisher = {CRC Press},
	editor = {Abdulla, Aza and Rai, G. S.},
	collaborator = {Black, David},
	year = {2022},
	note = {OCLC: 1301430739},
}

@article{auctores_publishing_llc_what_2021,
	title = {What {Are} the {Other} {Energy} {Functions} of the {Heart} {That} {We} {Need} {To} {Know} {Besides} {It} {Being} {A} {Blood} {Pump}?},
	volume = {04},
	issn = {26410419},
	url = {https://auctoresonline.org/article/what-are-the-other-energy-functions-of-the-heart-that-we-need-to-know-besides-it-being-a-blood-pump},
	doi = {10.31579/2641-0419/218},
	abstract = {This article will be based on the commandments of Hippocrates (460 bce – 375 bce), father of medicine, who said that we must study the oldest medicines before the current medicine practiced today.},
	language = {en},
	number = {15},
	urldate = {2024-05-14},
	journal = {Clinical Cardiology and Cardiovascular Interventions},
	author = {Alves, Rua},
	editor = {{Auctores Publishing LLC}},
	month = sep,
	year = {2021},
	pages = {01--05},
	file = {Alves - 2021 - What Are the Other Energy Functions of the Heart T.pdf:C\:\\Users\\junpi\\Zotero\\storage\\9DDIHJEK\\Alves - 2021 - What Are the Other Energy Functions of the Heart T.pdf:application/pdf},
}

@article{scannali_s-22-6_2023,
	title = {S-22-6: {RENAL} {EXPRESSION} {OF} {MICRORNAS} {AND} {THEIR} {ASSOCIATION} {WITH} {BLOOD} {PRESSURE} {REGULATION} - {INSIGHTS} {FROM} {SMALL} {RNA}-{SEQUENCING} {OF} 493 {HUMAN} {KIDNEYS}},
	volume = {41},
	issn = {0263-6352, 1473-5598},
	shorttitle = {S-22-6},
	url = {https://journals.lww.com/10.1097/01.hjh.0000913244.62614.98},
	doi = {10.1097/01.hjh.0000913244.62614.98},
	abstract = {The kidney is a critical regulator of blood pressure (BP) and a contributor to cardiovascular health. Recently, microRNAs (miRNAs) have emerged as potential mediators of genetic predisposition to cardiovascular and kidney disorders, yet their overall role in blood pressure control has not been fully characterised. We sought to identify and catalogue all renal miRNAs, investigate which of them are genetically regulated and assess whether their expression-modifying single nucleotide polymorphisms (SNPs) overlap with genetic variants associated with BP in previous genome-wide association studies (GWAS).
              We first characterised the entire renal miRNA transcriptome through de novo small RNA-sequencing of 493 human kidney samples. We then integrated these expression profiles with genotype information to perform expression quantitative trait loci (eQTL) analysis - the largest of its kind - and identify genetically regulated miRNAs and their regulatory SNPs. We then examined the extent to which miRNA-regulating variants overlapped with the curated list of BP-associated GWAS SNPs.
              We identified 1,459 mature miRNAs expressed in the human kidney, and the top 50 most highly expressed miRNAs accounted for 24.2\% of the measured expression. We also discovered that 78\% of miRNA genes expressed in the kidney were intragenic to other genes and 58\% mapped to an intron of those genes. After correction for multiple testing, our eQTL analysis had identified 140 genetically regulated miRNAs in the kidney. They were controlled by 19,901 unique SNPs (eSNPs) with a total of 21,805 miRNA-eSNP pairs. Functional annotation of miRNA eSNPs demonstrated 2.54-fold enrichment for kidney enhancer regions and 1.69-fold enrichment for kidney promoters when compared to randomly selected SNPs. Through overlap with GWAS SNPs for systolic, diastolic and pulse pressures, we identified 8 kidney BP miRNA eSNPs responsible for the regulation of 9 mature miRNAs.
              Collectively, we generated a catalogue of miRNAs expressed in the human kidney, annotated novel kidney relevant miRNAs and their regulatory variants and discovered 9 renal microRNAs that may act as mediators of genetic predisposition to high BP.},
	language = {en},
	number = {Suppl 1},
	urldate = {2024-05-14},
	journal = {Journal of Hypertension},
	author = {Scannali, David and Xu, Xiaoguang and Eales, James M and Drzal, Maciej and Rainey, Timothy and Bogdanski, Pawel and Wystrychowski, Wojciech and Zywiec, Joanna and Szczechowska, Ewa Zukowska and Guzik, Tomasz J and Morris, Andrew P and Charchar, Fadi J and Tomaszewski, Maciej},
	month = jan,
	year = {2023},
	pages = {e54},
}

@article{pepe_microvascular_2023,
	title = {Microvascular {Skeletal}-{Muscle} {Crosstalk} in {Health} and {Disease}},
	volume = {24},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1422-0067},
	url = {https://www.mdpi.com/1422-0067/24/13/10425},
	doi = {10.3390/ijms241310425},
	abstract = {As an organ system, skeletal muscle is essential for the generation of energy that underpins muscle contraction, plays a critical role in controlling energy balance and insulin-dependent glucose homeostasis, as well as vascular well-being, and regenerates following injury. To achieve homeostasis, there is requirement for “cross-talk” between the myogenic and vascular components and their regulatory factors that comprise skeletal muscle. Accordingly, this review will describe the following: [a] the embryonic cell-signaling events important in establishing vascular and myogenic cell-lineage, the cross-talk between endothelial cells (EC) and myogenic precursors underpinning the development of muscle, its vasculature and the satellite-stem-cell (SC) pool, and the EC–SC cross-talk that maintains SC quiescence and localizes ECs to SCs and angio-myogenesis postnatally; [b] the vascular–myocyte cross-talk and the actions of insulin on vasodilation and capillary surface area important for the uptake of glucose/insulin by myofibers and vascular homeostasis, the microvascular-myocyte dysfunction that characterizes the development of insulin resistance, diabetes and hypertension, and the actions of estrogen on muscle vasodilation and growth in adults; [c] the role of estrogen in utero on the development of fetal skeletal-muscle microvascularization and myofiber hypertrophy required for metabolic/vascular homeostasis after birth; [d] the EC–SC interactions that underpin myofiber vascular regeneration post-injury; and [e] the role of the skeletal-muscle vasculature in Duchenne muscular dystrophy.},
	language = {en},
	number = {13},
	urldate = {2024-05-26},
	journal = {International Journal of Molecular Sciences},
	author = {Pepe, Gerald J. and Albrecht, Eugene D.},
	month = jun,
	year = {2023},
	pages = {10425},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\9Q4B3JT9\\Pepe and Albrecht - 2023 - Microvascular Skeletal-Muscle Crosstalk in Health .pdf:application/pdf},
}

@article{haffner_emerging_2023,
	title = {The emerging role of the {HTRA1} protease in brain microvascular disease},
	volume = {2},
	issn = {2813-3919},
	url = {https://www.frontiersin.org/articles/10.3389/frdem.2023.1146055/full},
	doi = {10.3389/frdem.2023.1146055},
	abstract = {Pathologies of the brain microvasculature, often referred to as cerebral small-vessel disease, are important contributors to vascular dementia, the second most common form of dementia in aging societies. In addition to their role in acute ischemic and hemorrhagic stroke, they have emerged as major cause of age-related cognitive decline in asymptomatic individuals. A central histological finding in these pathologies is the disruption of the vessel architecture including thickening of the vessel wall, narrowing of the vessel lumen and massive expansion of the mural extracellular matrix. The underlying molecular mechanisms are largely unknown, but from the investigation of several disease forms with defined etiology, high temperature requirement protein A1 (HTRA1), a secreted serine protease degrading primarily matrisomal substrates, has emerged as critical factor and potential therapeutic target. A genetically induced loss of HTRA1 function in humans is associated with cerebral autosomal-recessive arteriopathy with subcortical infarcts and leukoencephalopathy (CARASIL), a rare, hereditary form of brain microvascular disease. Recently, proteomic studies on cerebral amyloid angiopathy (CAA), a common cause of age-related dementia, and cerebral autosomal-dominant arteriopathy with subcortical infarcts and leukoencephalopathy (CADASIL), the most prevalent monogenic small-vessel disease, have provided evidence for an impairment of HTRA1 activity through sequestration into pathological protein deposits, suggesting an alternative mechanism of HTRA1 inactivation and expanding the range of diseases with HTRA1 involvement. Further investigations of the mechanisms of HTRA1 regulation in the brain microvasculature might spawn novel strategies for the treatment of small-vessel pathologies.},
	urldate = {2024-05-26},
	journal = {Frontiers in Dementia},
	author = {Haffner, Christof},
	month = apr,
	year = {2023},
	pages = {1146055},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\CXQGTRDH\\Haffner - 2023 - The emerging role of the HTRA1 protease in brain m.pdf:application/pdf},
}

@article{rusanova_role_2022,
	title = {The role of microcirculation in the conducting structures of the nervous system in patients with vibration disease burdened by metabolic syndrome},
	volume = {101},
	issn = {2412-0650, 0016-9900},
	url = {https://www.rjhas.ru/jour/article/view/2546},
	doi = {10.47470/0016-9900-2022-101-9-1035-1042},
	abstract = {Introduction. The study of microcirculation processes in peripheral nerve damage remains a necessary area of experimental and clinical research, because the microvascular bed is one of the most important systems in which the disease manifests itself in the early stages. The aim of the study is to identify the role of microcirculation disorders in the state of central and peripheral conductive structures in patients with vibration disease (VD) associated with combined exposure to general and local vibration, and burdened with metabolic syndrome (MS) and diabetes mellitus (DM). Materials and methods. Group 1 included patients with VD associated with combined exposure to general and local vibration, group 2 - persons diagnosed with VD, burdened with MS, group 3 - with a diagnosis of VD, burdened with DM. At the 1st stage of the study, basal blood flow was studied, at the 2 nd stage - load functional tests (respiratory and occlusive). The state of sensory and motor axons of the nervous system was determined. Results. In patients of the examined groups, there was proved a relationship between the indicators of the state of peripheral nerves and central structures with the indicators of microcirculation, the state of the myogenic level of regulation, with the index of specific oxygen consumption and the index of relative perfusion oxygen saturation in the microcirculation. In patients with VD, burdened with MS and DM, an association was found between changes in axons with an indicator of the intensity of functioning of the regulatory systems of the microvascular bed, indicators of the levels of active regulation of microcirculation (myogenic, neurogenic and endothelial) and indicators characterizing the dynamic state of the microcirculation system. Limitations. The disadvantage of the study is the fact that the parameters of the microcirculation system determined in the peripheral departments were extrapolated to the central structures, and were not determined in the capillary network of the brain. Conclusion. Changes in the microcirculatory bed were established to be a link in the pathogenesis of demyelination processes in VB associated with the combined effects of general and local vibration, and vibration disease burdened with MS and DM.},
	number = {9},
	urldate = {2024-05-26},
	journal = {Hygiene and sanitation},
	author = {Rusanova, Dina V. and Kuks, Anna N. and Lakhman, Oleg L. and Slivnitsyna, Natalya V.},
	month = sep,
	year = {2022},
	pages = {1035--1042},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\5VIRHQQM\\Rusanova et al. - 2022 - The role of microcirculation in the conducting str.pdf:application/pdf},
}

@article{jan_advances_2022,
	title = {Advances in {Diagnosis} and {Pathophysiology} of {Microvascular} {Dysfunction}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2075-4418},
	url = {https://www.mdpi.com/2075-4418/12/3/620},
	doi = {10.3390/diagnostics12030620},
	abstract = {Microcirculation is the system that brings oxygen and nutrients to local cells and removes metabolic wastes [...]},
	language = {en},
	number = {3},
	urldate = {2024-05-26},
	journal = {Diagnostics},
	author = {Jan, Yih-Kuen},
	month = mar,
	year = {2022},
	pages = {620},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\RTTWAIJ8\\Jan - 2022 - Advances in Diagnosis and Pathophysiology of Micro.pdf:application/pdf},
}

@misc{sultan_microvasculature_2023,
	title = {Microvasculature {Segmentation} in {Human} {BioMolecular} {Atlas} {Program} ({HuBMAP})},
	url = {http://arxiv.org/abs/2308.03203},
	abstract = {Image segmentation serves as a critical tool across a range of applications, encompassing autonomous driving’s pedestrian detection and pre-operative tumor delineation in the medical sector. Among these applications, we focus on the National Institutes of Health’s (NIH) Human BioMolecular Atlas Program (HuBMAP), a significant initiative aimed at creating detailed cellular maps of the human body. In this study, we concentrate on segmenting various microvascular structures in human kidneys, utilizing 2D Periodic Acid-Schiff (PAS)-stained histology images. Our methodology begins with a foundational FastAI U-Net model, upon which we investigate alternative backbone architectures, delve into deeper models, and experiment with Feature Pyramid Networks. We rigorously evaluate these varied approaches by benchmarking their performance against our baseline U-Net model. This study thus offers a comprehensive exploration of cutting-edge segmentation techniques, providing valuable insights for future research in the field.},
	language = {en},
	urldate = {2024-05-27},
	publisher = {arXiv},
	author = {Sultan, Youssef and Wang, Yongqiang and Scanlon, James and D'lima, Lisa},
	month = aug,
	year = {2023},
	note = {arXiv:2308.03203 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Machine Learning},
	file = {Sultan et al. - 2023 - Microvasculature Segmentation in Human BioMolecula.pdf:C\:\\Users\\junpi\\Zotero\\storage\\GDUDVEY6\\Sultan et al. - 2023 - Microvasculature Segmentation in Human BioMolecula.pdf:application/pdf},
}

@incollection{gopalan_renal_2022,
	title = {Renal physiology},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-823421-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128234211000056},
	language = {en},
	urldate = {2024-05-28},
	booktitle = {Biology of {Cardiovascular} and {Metabolic} {Diseases}},
	publisher = {Elsevier},
	author = {Gopalan, Chaya and Kirk, Erik},
	year = {2022},
	doi = {10.1016/B978-0-12-823421-1.00005-6},
	pages = {123--140},
}

@misc{haug_multi-omic_2022,
	title = {Multi-omic {Analysis} of {Primary} {Human} {Kidney} {Tissues} {Identifies} {Medulla}-{Specific} {Gene} {Expression} {Patterns}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.10.05.508277},
	doi = {10.1101/2022.10.05.508277},
	abstract = {Abstract
          The renal medulla is a specialized region of the kidney with important homeostatic functions. It has also been implicated in genetic and developmental disorders and ischemic and drug-induced injuries. Despite its role in kidney function and disease, the medulla’s baseline gene expression and epigenomic signatures have not been well described in the adult human kidney. Here we generate and analyze gene expression (RNA-seq), chromatin accessibility (ATAC-seq) and chromatin conformation (Hi-C) data from adult human kidney cortex and medulla. Using data from our carefully annotated specimens, we assign samples in the larger public GTEx database to cortex and medulla, thereby identifying several misassignments and extracting meaningful medullary gene expression signatures. Using integrated analysis of gene expression, chromatin accessibility and conformation profiles, we reveal insights into medulla development and function. Our datasets will also provide a valuable resource for researchers in the GWAS community for functional annotation of genetic variants.},
	language = {en},
	urldate = {2024-05-28},
	author = {Haug, Stefan and Muthusamy, Selvaraj and Li, Yong and Köttgen, Anna and Akilesh, Shreeram},
	month = oct,
	year = {2022},
	file = {Submitted Version:C\:\\Users\\junpi\\Zotero\\storage\\EK3985BZ\\Haug et al. - 2022 - Multi-omic Analysis of Primary Human Kidney Tissue.pdf:application/pdf},
}

@article{nankivell_importance_2020,
	title = {The {Importance} of {Kidney} {Medullary} {Tissue} for the {Accurate} {Diagnosis} of {BK} {Virus} {Allograft} {Nephropathy}},
	volume = {15},
	issn = {1555-9041, 1555-905X},
	url = {https://journals.lww.com/10.2215/CJN.13611119},
	doi = {10.2215/CJN.13611119},
	abstract = {Background and objectives
              The published tissue adequacy requirement of kidney medulla for BK virus allograft nephropathy diagnosis lacks systematic verification and competes against potential increased procedural risks from deeper sampling.
            
            
              Design, setting, participants, \& measurements
              We evaluated whether the presence of kidney medulla improved the diagnostic rate of BK nephropathy in 2244 consecutive biopsy samples from 856 kidney transplants with detailed histologic and virologic results.
            
            
              Results
              
                Medulla was present in 821 samples (37\%) and correlated with maximal core length (
                r
                =0.35;
                P
                {\textless}0.001). BK virus allograft nephropathy occurred in 74 (3\% overall) but increased to 5\% (42 of 821) with medulla compared with 2\% (32 of 1423) for cortical samples (
                P
                {\textless}0.001). Biopsy medulla was associated with infection after comprehensive multivariable adjustment of confounders, including core length, glomerular number, and number of cores (adjusted odds ratio, 1.81; 95\% confidence interval, 1.02 to 3.21;
                P
                =0.04). In viremic cases (
                n
                =275), medulla was associated with BK virus nephropathy diagnosis (39\% versus 19\% for cortex;
                P
                {\textless}0.001) and tissue polyomavirus load (Banff polyomavirus score 0.64±0.96 versus 0.33±1.00;
                P
                =0.006). Biopsy medulla was associated with BK virus allograft nephropathy using generalized estimating equation (odds ratio, 2.04; 95\% confidence interval, 1.05 to 3.96;
                n
                =275) and propensity matched score comparison (odds ratio, 2.24; 95\% confidence interval, 1.11 to 4.54;
                P
                =0.03 for 156 balanced pairs). Morphometric evaluation of Simian virus 40 large T immunohistochemistry found maximal infected tubules within the inner cortex and medullary regions (
                P
                {\textless}0.001 versus outer cortex).
              
            
            
              Conclusions
              Active BK virus replication concentrated around the corticomedullary junction can explain the higher detection rates for BK virus allograft nephropathy with deep sampling. The current adequacy requirement specifying targeting medulla can be justified to minimize a missed diagnosis from undersampling.},
	language = {en},
	number = {7},
	urldate = {2024-05-28},
	journal = {Clinical Journal of the American Society of Nephrology},
	author = {Nankivell, Brian J. and Renthawa, Jasveen and Shingde, Meena and Khan, Asrar},
	month = jul,
	year = {2020},
	pages = {1015--1023},
}

@article{sabate_arroyo_relationship_2020,
	title = {Relationship of endoscopic lesions of the renal papilla with type of renal stone and 24 h urine analysis},
	volume = {20},
	issn = {1471-2490},
	url = {https://bmcurol.biomedcentral.com/articles/10.1186/s12894-020-00615-4},
	doi = {10.1186/s12894-020-00615-4},
	abstract = {Abstract
            
              Background
              Our purpose was to study the relationship of the 3 different types of endoscopic calcifications of the renal papilla (Randall’s plaque, intratubular calcification, papillary crater) with the type of stone and urine analysis.
            
            
              Methods
              
                This prospective study examined 41 patients (age range: 18 to 80 years) who received retrograde intrarenal surgery (RIRS) for renal lithiasis (mean stone size: 15.3 ± 7.2 mm). The renal papilla injuries were endoscopically classified as Randall’s plaque, intratubular calcification, or papillary crater. Calculi were classified as uric acid, calcium oxalate monohydrate (COM; papillary and cavity), calcium oxalate dihydrate (COD), or calcium phosphate (CP). A 24 h urine analysis of calcium, oxalate, citrate, phosphate, and pH was performed in all patients. The relationship of each type of papillary injury with type of stone and urine chemistry was determined. Fisher’s exact test and Student’s t-test were used to determine the significance of relationships, and a
                p
                value below 0.05 was considered significant.
              
            
            
              Results
              
                The most common injury was tubular calcification (78\%), followed by Randall’s plaque (58\%), and papillary crater (39\%). There was no significant relationship of Randall’s plaque with type of stone. However, endoscopic intratubular calcification (
                p
                 = 0.025) and papillary crater (
                p
                 = 0.041) were more common in patients with COD and CP stones. There were also significant relationships of papillary crater with hypercalciuria (
                p
                 = 0.036) and hyperoxaluria (
                p
                 = 0.024), and of Randall’s plaque with hypocitraturia (
                p
                 = 0.005).
              
            
            
              Conclusions
              There are certain specific relationships between the different types of papillary calcifications that were endoscopically detected with stone chemistry and urine analysis. COD and CP stones were associated with endoscopic tubular calcifications and papillary craters. Hypercalciuria was associated with tubular calcification, and hypocitraturia was associated with Randall’s plaque.},
	language = {en},
	number = {1},
	urldate = {2024-05-28},
	journal = {BMC Urology},
	author = {Sabaté Arroyo, X.A. and Grases Freixedas, F. and Bauzà Quetglas, J. L. and Guimerà Garcia, J. and Pieras Ayala, E.},
	month = dec,
	year = {2020},
	pages = {46},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\4ENU722M\\Sabaté Arroyo et al. - 2020 - Relationship of endoscopic lesions of the renal pa.pdf:application/pdf},
}

@article{luxen_unique_2023,
	title = {Unique {miRNome} and transcriptome profiles underlie microvascular heterogeneity in mouse kidney},
	volume = {325},
	issn = {1931-857X, 1522-1466},
	url = {https://journals.physiology.org/doi/10.1152/ajprenal.00005.2023},
	doi = {10.1152/ajprenal.00005.2023},
	abstract = {Renal endothelial cells display a high level of heterogeneity depending on the (micro)vascular bed they reside in. The molecular basis contributing to these differences is poorly understood yet of high importance to increase understanding of microvascular engagement in the kidney in health and disease. This report describes m(icro)RNA expression profiles of microvascular beds in the mouse renal cortex and uncovers microvascular compartment-specific m(icro)RNAs and miRNA-mRNA pairs, thereby revealing important molecular mechanisms underlying renal microvascular heterogeneity.
          , 
            Endothelial cells in blood vessels in the kidney exert different functions depending on the (micro)vascular bed they are located in. The present study aimed to investigate microRNA and mRNA transcription patterns that underlie these differences. We zoomed in on microvascular compartments in the mouse renal cortex by laser microdissecting the microvessels prior to small RNA- and RNA-sequencing analyses. By these means, we characterized microRNA and mRNA transcription profiles of arterioles, glomeruli, peritubular capillaries, and postcapillary venules. Quantitative RT-PCR, in situ hybridization, and immunohistochemistry were used to validate sequencing results. Unique microRNA and mRNA transcription profiles were found in all microvascular compartments, with dedicated marker microRNAs and mRNAs showing enriched transcription in a single microvascular compartment. In situ hybridization validated the localization of microRNAs mmu-miR-140-3p in arterioles, mmu-miR-322-3p in glomeruli, and mmu-miR-451a in postcapillary venules. Immunohistochemical staining showed that von Willebrand factor protein was mainly expressed in arterioles and postcapillary venules, whereas GABRB1 expression was enriched in glomeruli, and IGF1 was enriched in postcapillary venules. More than 550 compartment-specific microRNA-mRNA interaction pairs were identified that carry functional implications for microvascular behavior. In conclusion, our study identified unique microRNA and mRNA transcription patterns in microvascular compartments of the mouse kidney cortex that underlie microvascular heterogeneity. These patterns provide important molecular information for future studies into differential microvascular engagement in health and disease.
            NEW \& NOTEWORTHY Renal endothelial cells display a high level of heterogeneity depending on the (micro)vascular bed they reside in. The molecular basis contributing to these differences is poorly understood yet of high importance to increase understanding of microvascular engagement in the kidney in health and disease. This report describes m(icro)RNA expression profiles of microvascular beds in the mouse renal cortex and uncovers microvascular compartment-specific m(icro)RNAs and miRNA-mRNA pairs, thereby revealing important molecular mechanisms underlying renal microvascular heterogeneity.},
	language = {en},
	number = {3},
	urldate = {2024-06-01},
	journal = {American Journal of Physiology-Renal Physiology},
	author = {Luxen, Matthijs and Zwiers, Peter J. and Meester, Femke and Jongman, Rianne M. and Kuiper, Timara and Moser, Jill and Pultar, Marianne and Skalicky, Susanna and Diendorfer, Andreas B. and Hackl, Matthias and Van Meurs, Matijs and Molema, Grietje},
	month = sep,
	year = {2023},
	pages = {F299--F316},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\Z5KC9CQA\\Luxen et al. - 2023 - Unique miRNome and transcriptome profiles underlie.pdf:application/pdf},
}

@article{savedchuk_targeting_2023,
	title = {Targeting {Glomerular} {Hemodynamics} for {Kidney} {Protection}},
	volume = {30},
	issn = {29498139},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2949813922000283},
	doi = {10.1053/j.akdh.2022.12.003},
	language = {en},
	number = {2},
	urldate = {2024-06-01},
	journal = {Advances in Kidney Disease and Health},
	author = {Savedchuk, Solomiia and Phachu, Deep and Shankar, Mythri and Sparks, Matthew A. and Harrison-Bernard, Lisa M.},
	month = mar,
	year = {2023},
	pages = {71--84},
}

@article{goligorsky_emerging_2022,
	title = {Emerging {Insights} into {Glomerular} {Vascular} {Pole} and {Microcirculation}},
	volume = {33},
	issn = {1046-6673, 1533-3450},
	url = {https://journals.lww.com/10.1681/ASN.2022030354},
	doi = {10.1681/ASN.2022030354},
	abstract = {The glomerular vascular pole is the gate for the afferent and efferent arterioles and mesangial cells and a frequent location of peripolar cells with an unclear function. It has been studied in definitive detail for {\textgreater}30 years, and functionally interrogated in the context of signal transduction from the macula densa to the mesangial cells and afferent arteriolar smooth muscle cells from 10 to 20 years ago. Two recent discoveries shed additional light on the vascular pole, with possibly far-reaching implications. One, which uses novel serial section electron microscopy, reveals a shorter capillary pathway between the basins of the afferent and efferent arterioles. Such a pathway, when patent, may short-circuit the multitude of capillaries in the glomerular tuft. Notably, this shorter capillary route is enclosed within the glomerular mesangium. The second study used anti-Thy1.1–induced mesangiolysis and intravital microscopy to unequivocally establish
              in vivo
              the long-suspected contractile function of mesangial cells, which have the ability to change the geometry and curvature of glomerular capillaries. These studies led me to hypothesize the existence of a glomerular perfusion rheostat, in which the shorter path periodically fluctuates between being more and less patent. This action reduces or increases blood flow through the entire glomerular capillary tuft. A corollary is that the GFR is a net product of balance between the states of capillary perfusion, and that deviations from the balanced state would increase or decrease GFR. Taken together, these studies may pave the way to a more profound understanding of glomerular microcirculation under basal conditions and in progression of glomerulopathies.},
	language = {en},
	number = {9},
	urldate = {2024-06-01},
	journal = {Journal of the American Society of Nephrology},
	author = {Goligorsky, Michael S.},
	month = sep,
	year = {2022},
	pages = {1641--1648},
}

@article{ergin_kidney_2021,
	title = {Kidney {Microcirculation} as a {Target} for {Innovative} {Therapies} in {AKI}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-0383},
	url = {https://www.mdpi.com/2077-0383/10/18/4041},
	doi = {10.3390/jcm10184041},
	abstract = {Acute kidney injury (AKI) is a serious multifactorial conditions accompanied by the loss of function and damage. The renal microcirculation plays a crucial role in maintaining the kidney’s functional and structural integrity for oxygen and nutrient supply and waste product removal. However, alterations in microcirculation and oxygenation due to renal perfusion defects, hypoxia, renal tubular, and endothelial damage can result in AKI and the loss of renal function regardless of systemic hemodynamic changes. The unique structural organization of the renal microvasculature and the presence of autoregulation make it difficult to understand the mechanisms and the occurrence of AKI following disorders such as septic, hemorrhagic, or cardiogenic shock; ischemia/reperfusion; chronic heart failure; cardiorenal syndrome; and hemodilution. In this review, we describe the organization of microcirculation, autoregulation, and pathophysiological alterations leading to AKI. We then suggest innovative therapies focused on the protection of the renal microcirculation and oxygenation to prevent AKI.},
	language = {en},
	number = {18},
	urldate = {2024-06-01},
	journal = {Journal of Clinical Medicine},
	author = {Ergin, Bülent and Akin, Sakir and Ince, Can},
	month = sep,
	year = {2021},
	pages = {4041},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\9AI8Y3KH\\Ergin et al. - 2021 - Kidney Microcirculation as a Target for Innovative.pdf:application/pdf},
}

@article{hanna_whole_2020,
	title = {Whole {Slide} {Imaging}: {Technology} and {Applications}},
	volume = {27},
	issn = {1072-4109},
	shorttitle = {Whole {Slide} {Imaging}},
	url = {https://journals.lww.com/10.1097/PAP.0000000000000273},
	doi = {10.1097/PAP.0000000000000273},
	abstract = {Pathology has beneﬁted from advanced innovation with novel technology to implement a digital solution. Whole slide imaging is a disruptive technology where glass slides are scanned to produce digital images. There have been signiﬁcant advances in whole slide scanning hardware and software that have allowed for ready access of whole slide images. The digital images, or whole slide images, can be viewed comparable to glass slides in a microscope, as digital ﬁles. Whole slide imaging has increased in adoption among pathologists, pathology departments, and scientists for clinical, educational, and research initiatives. Worldwide usage of whole slide imaging has grown signiﬁcantly. Pathology regulatory organizations (ie, College of American Pathologists) have put forth guidelines for clinical validation, and the US Food and Drug Administration have also approved whole slide imaging for primary diagnosis. This article will review the digital pathology ecosystem and discuss clinical and nonclinical applications of its use.},
	language = {en},
	number = {4},
	urldate = {2024-06-02},
	journal = {Advances in Anatomic Pathology},
	author = {Hanna, Matthew G. and Parwani, Anil and Sirintrapun, Sahussapont Joseph},
	month = jul,
	year = {2020},
	pages = {251--259},
	file = {Hanna et al. - 2020 - Whole Slide Imaging Technology and Applications.pdf:C\:\\Users\\junpi\\Zotero\\storage\\ZDK3MIPR\\Hanna et al. - 2020 - Whole Slide Imaging Technology and Applications.pdf:application/pdf},
}

@article{li_hardware-software_2023,
	title = {Hardware-software co-design of an open-source automatic multimodal whole slide histopathology imaging system},
	volume = {28},
	issn = {1083-3668},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-28/issue-02/026501/Hardware-software-co-design-of-an-open-source-automatic-multimodal/10.1117/1.JBO.28.2.026501.full},
	doi = {10.1117/1.JBO.28.2.026501},
	number = {02},
	urldate = {2024-06-02},
	journal = {Journal of Biomedical Optics},
	author = {Li, Bin and Nelson, Michael S. and Chacko, Jenu V. and Cudworth, Nathan and Eliceiri, Kevin W.},
	month = feb,
	year = {2023},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\RMTTGTSJ\\Li et al. - 2023 - Hardware-software co-design of an open-source auto.pdf:application/pdf},
}

@incollection{wu_image_2023,
	title = {Image {Segmentation}},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-821049-9},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128210499000034},
	language = {en},
	urldate = {2024-06-03},
	booktitle = {Microscope {Image} {Processing}},
	publisher = {Elsevier},
	author = {Wu, Qiang and Castleman, Kenneth R.},
	year = {2023},
	doi = {10.1016/B978-0-12-821049-9.00003-4},
	pages = {119--152},
}

@article{wang_comprehensive_2022,
	title = {A {Comprehensive} {Review} of {Modern} {Object} {Segmentation} {Approaches}},
	volume = {13},
	issn = {1572-2740, 1572-2759},
	url = {http://www.nowpublishers.com/article/Details/CGV-097},
	doi = {10.1561/0600000097},
	language = {en},
	number = {2-3},
	urldate = {2024-06-03},
	journal = {Foundations and Trends® in Computer Graphics and Vision},
	author = {Wang, Yuanbo and Ahsan, Unaiza and Li, Hanyan and Hagen, Matthew},
	year = {2022},
	pages = {111--283},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\NTUVPAZM\\Wang et al. - 2022 - A Comprehensive Review of Modern Object Segmentati.pdf:application/pdf},
}

@article{fan_image_2023,
	title = {Image semantic segmentation using deep learning technique},
	volume = {4},
	issn = {2755-2721, 2755-273X},
	url = {https://ace.ewapublishing.org/article.html?pk=8a91acd8c046477a82384ce0896a8b15},
	doi = {10.54254/2755-2721/4/2023439},
	abstract = {With the deepening research on image understanding in many application fields, including auto drive system, unmanned aerial vehicle (UAV) landing point judgment, virtual reality wearable devices, etc., computer vision and machine learning researchers are paying more and more attention to image semantic segmentation (ISS). In this paper, according to the different region generation algorithms, the regional classification image semantic segmentation methods are classified into the candidate region method and the segmentation mask method, according to different learning methods, the image semantic segmentation methods based on super pixels are divided into fully supervised learning method and weakly supervised learning method. The typical algorithms in these various categories are summarized and compared. In addition, this paper also systematically expounds the role of DL technology in the field of ISS, and discusses the main challenges and future development prospects in this field.},
	number = {1},
	urldate = {2024-06-03},
	journal = {Applied and Computational Engineering},
	author = {Fan, Yifei},
	month = jun,
	year = {2023},
	pages = {810--817},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\PUWMWHZ2\\Fan - 2023 - Image semantic segmentation using deep learning te.pdf:application/pdf},
}

@inproceedings{wang_traffic_2023,
	address = {Wuhan, China},
	title = {A traffic image semantic segmentation algorithm based on {UNET}},
	isbn = {978-1-5106-6347-3 978-1-5106-6348-0},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12610/2671074/A-traffic-image-semantic-segmentation-algorithm-based-on-UNET/10.1117/12.2671074.full},
	doi = {10.1117/12.2671074},
	urldate = {2024-06-03},
	booktitle = {Third {International} {Conference} on {Artificial} {Intelligence} and {Computer} {Engineering} ({ICAICE} 2022)},
	publisher = {SPIE},
	author = {Wang, Chunli and Zeng, Botao and Gao, Jindie and Peng, Ge and Yang, Wei},
	editor = {Li, Xiaoli},
	month = apr,
	year = {2023},
	pages = {35},
}

@article{zhang_image_2023,
	title = {Image {Style} {Transfer} based on {DeepLabV3}+ {Semantic} {Segmentation}},
	volume = {39},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0},
	issn = {2791-0210},
	url = {https://drpress.org/ojs/index.php/HSET/article/view/6729},
	doi = {10.54097/hset.v39i.6729},
	abstract = {Image style transfer has always been a popular research method in the computer vision community, which aims to learn the style of a given image and the content distribution of other images to generate new images with both the above style and content. Thanks to the rapid development of convolutional neural networks, the accuracy, and visualization of image segmentation and migration have been continuously improved, but there is still the problem of local content distortion. Some recent works introduce the segmentation branch to obtain pixel-level content information in order to obtain a more perfect transfer effect. In this paper, we use the VGG19 convolutional neural network model to extract high-level feature maps representing image content information and perform image style transfer based on the DeepLabV3+ semantic segmentation network, which can move images to the same or similar semantic regions during the entire transmission process. In order to prevent content distortion after image migration, we also introduce an affine function to control the content change of the image during image migration. Extensive experimental results show that the method in this paper can further clarify the segmentation boundary and improve the semantic accuracy of the transferred image. In addition, we also evaluated the expectations of different individuals on the degree of style transfer. By distributing the survey, this paper demonstrates that the method described in this study results in better image quality, more in line with the expectations of the majority of respondents.},
	urldate = {2024-06-03},
	journal = {Highlights in Science, Engineering and Technology},
	author = {Zhang, Jixiang},
	month = apr,
	year = {2023},
	pages = {1203--1213},
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {Machine learning},
}

@incollection{yang_deep_2023,
	title = {Deep {Learning} in {Medical} {Imaging}},
	volume = {18},
	copyright = {https://creativecommons.org/licenses/by/3.0/legalcode},
	isbn = {978-1-80356-950-5 978-1-80356-951-2},
	url = {https://www.intechopen.com/chapters/87248},
	abstract = {Medical image processing tools play an important role in clinical routine in helping doctors to establish whether a patient has or does not have a certain disease. To validate the diagnosis results, various clinical parameters must be defined. In this context, several algorithms and mathematical tools have been developed in the last two decades to extract accurate information from medical images or signals. Traditionally, the extraction of features using image processing from medical data are time-consuming which requires human interaction and expert validation. The segmentation of medical images, the classification of medical images, and the significance of deep learning-based algorithms in disease detection are all topics covered in this chapter.},
	language = {en},
	urldate = {2024-06-06},
	booktitle = {Artificial {Intelligence}},
	publisher = {IntechOpen},
	author = {Benameur, Narjes and Mahmoudi, Ramzi},
	editor = {Yang, Jucheng and Chen, Yarui and Zhao, Tingting and Wang, Yuan and Pan, Xuran},
	month = nov,
	year = {2023},
	doi = {10.5772/intechopen.111686},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\GPPTCIMW\\Benameur and Mahmoudi - 2023 - Deep Learning in Medical Imaging.pdf:application/pdf},
}

@article{sistaninejhad_review_2023,
	title = {A {Review} {Paper} about {Deep} {Learning} for {Medical} {Image} {Analysis}},
	volume = {2023},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1748-6718, 1748-670X},
	url = {https://www.hindawi.com/journals/cmmm/2023/7091301/},
	doi = {10.1155/2023/7091301},
	abstract = {Medical imaging refers to the process of obtaining images of internal organs for therapeutic purposes such as discovering or studying diseases. The primary objective of medical image analysis is to improve the efficacy of clinical research and treatment options. Deep learning has revamped medical image analysis, yielding excellent results in image processing tasks such as registration, segmentation, feature extraction, and classification. The prime motivations for this are the availability of computational resources and the resurgence of deep convolutional neural networks. Deep learning techniques are good at observing hidden patterns in images and supporting clinicians in achieving diagnostic perfection. It has proven to be the most effective method for organ segmentation, cancer detection, disease categorization, and computer-assisted diagnosis. Many deep learning approaches have been published to analyze medical images for various diagnostic purposes. In this paper, we review the work exploiting current state-of-the-art deep learning approaches in medical image processing. We begin the survey by providing a synopsis of research works in medical imaging based on convolutional neural networks. Second, we discuss popular pretrained models and general adversarial networks that aid in improving convolutional networks’ performance. Finally, to ease direct evaluation, we compile the performance metrics of deep learning models focusing on COVID-19 detection and child bone age prediction.},
	language = {en},
	urldate = {2024-06-06},
	journal = {Computational and Mathematical Methods in Medicine},
	author = {Sistaninejhad, Bagher and Rasi, Habib and Nayeri, Parisa},
	editor = {Moraru, Luminita},
	month = may,
	year = {2023},
	pages = {1--10},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\SIG4AQZB\\Sistaninejhad et al. - 2023 - A Review Paper about Deep Learning for Medical Ima.pdf:application/pdf},
}

@misc{azad_medical_2022,
	title = {Medical {Image} {Segmentation} {Review}: {The} success of {U}-{Net}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Medical {Image} {Segmentation} {Review}},
	url = {https://arxiv.org/abs/2211.14830},
	doi = {10.48550/ARXIV.2211.14830},
	abstract = {Automatic medical image segmentation is a crucial topic in the medical domain and successively a critical counterpart in the computer-aided diagnosis paradigm. U-Net is the most widespread image segmentation architecture due to its flexibility, optimized modular design, and success in all medical image modalities. Over the years, the U-Net model achieved tremendous attention from academic and industrial researchers. Several extensions of this network have been proposed to address the scale and complexity created by medical tasks. Addressing the deficiency of the naive U-Net model is the foremost step for vendors to utilize the proper U-Net variant model for their business. Having a compendium of different variants in one place makes it easier for builders to identify the relevant research. Also, for ML researchers it will help them understand the challenges of the biological tasks that challenge the model. To address this, we discuss the practical aspects of the U-Net model and suggest a taxonomy to categorize each network variant. Moreover, to measure the performance of these strategies in a clinical application, we propose fair evaluations of some unique and famous designs on well-known datasets. We provide a comprehensive implementation library with trained models for future research. In addition, for ease of future studies, we created an online list of U-Net papers with their possible official implementation. All information is gathered in https://github.com/NITR098/Awesome-U-Net repository.},
	urldate = {2024-06-06},
	publisher = {arXiv},
	author = {Azad, Reza and Aghdam, Ehsan Khodapanah and Rauland, Amelie and Jia, Yiwei and Avval, Atlas Haddadi and Bozorgpour, Afshin and Karimijafarbigloo, Sanaz and Cohen, Joseph Paul and Adeli, Ehsan and Merhof, Dorit},
	year = {2022},
	note = {Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.IV)},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\MNKINS45\\Azad et al. - 2022 - Medical Image Segmentation Review The success of .pdf:application/pdf},
}

@article{celeghin_convolutional_2023,
	title = {Convolutional neural networks for vision neuroscience: significance, developments, and outstanding issues},
	volume = {17},
	issn = {1662-5188},
	shorttitle = {Convolutional neural networks for vision neuroscience},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2023.1153572/full},
	doi = {10.3389/fncom.2023.1153572},
	abstract = {Convolutional Neural Networks (CNN) are a class of machine learning models predominately used in computer vision tasks and can achieve human-like performance through learning from experience. Their striking similarities to the structural and functional principles of the primate visual system allow for comparisons between these artificial networks and their biological counterparts, enabling exploration of how visual functions and neural representations may emerge in the real brain from a limited set of computational principles. After considering the basic features of CNNs, we discuss the opportunities and challenges of endorsing CNNs as
              in silico
              models of the primate visual system. Specifically, we highlight several emerging notions about the anatomical and physiological properties of the visual system that still need to be systematically integrated into current CNN models. These tenets include the implementation of parallel processing pathways from the early stages of retinal input and the reconsideration of several assumptions concerning the serial progression of information flow. We suggest design choices and architectural constraints that could facilitate a closer alignment with biology provide causal evidence of the predictive link between the artificial and biological visual systems. Adopting this principled perspective could potentially lead to new research questions and applications of CNNs beyond modeling object recognition.},
	urldate = {2024-06-06},
	journal = {Frontiers in Computational Neuroscience},
	author = {Celeghin, Alessia and Borriero, Alessio and Orsenigo, Davide and Diano, Matteo and Méndez Guerrero, Carlos Andrés and Perotti, Alan and Petri, Giovanni and Tamietto, Marco},
	month = jul,
	year = {2023},
	pages = {1153572},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\DHGNWWIW\\Celeghin et al. - 2023 - Convolutional neural networks for vision neuroscie.pdf:application/pdf},
}

@article{jasim_towards_2023,
	title = {Towards classification of images by using block-based {CNN}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by-sa/4.0},
	issn = {2302-9285, 2089-3191},
	url = {https://beei.org/index.php/EEI/article/view/4806},
	doi = {10.11591/eei.v12i1.4806},
	abstract = {Image classification is the process of assigning labeling to the input images to a fixed set of categories; however, assigning labels to the image is difficult by using the traditional method because of the large number of images. To solve this problem, we will resort to deep learning techniques. Which is enables computers to recognize and extract visual characteristics. The convolutional neural network (CNN) is a deep neural network used for many purposes, such as image classification, detection, and face recognition, due to its high-performance accuracy in classification and detection tasks. In this paper, we develop CNN based on the transfer learning approach for image classification. The network comprises two types of transfer learning, ResNet and DenseNet, as building blocks of the network with an multilayer perceptron (MLP) classifier. The proposed method does not need to preprocess before these datasets that input into the network. It was train on two datasets: the Cifar-10 and the Sign-Traffic datasets. We conclude that the proposed method achieves the best performance compared with other states of the art. The accuracy gained is 97.45\% and 99.45\%, respectively, where the proposed CNN increased the accuracy compared to other methods by 3\%.},
	number = {1},
	urldate = {2024-06-06},
	journal = {Bulletin of Electrical Engineering and Informatics},
	author = {Jasim, Retaj Matroud and Atia, Tayseer Salman},
	month = feb,
	year = {2023},
	pages = {373--379},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\5FWYQEPS\\Jasim and Atia - 2023 - Towards classification of images by using block-ba.pdf:application/pdf},
}

@article{shlezinger_model-based_2023,
	title = {Model-{Based} {Deep} {Learning}},
	volume = {111},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219, 1558-2256},
	url = {https://ieeexplore.ieee.org/document/10056957/},
	doi = {10.1109/JPROC.2023.3247480},
	number = {5},
	urldate = {2024-06-06},
	journal = {Proceedings of the IEEE},
	author = {Shlezinger, Nir and Whang, Jay and Eldar, Yonina C. and Dimakis, Alexandros G.},
	month = may,
	year = {2023},
	pages = {465--499},
	file = {Submitted Version:C\:\\Users\\junpi\\Zotero\\storage\\WUQTNJZE\\Shlezinger et al. - 2023 - Model-Based Deep Learning.pdf:application/pdf},
}

@article{iqbal_analyses_2023,
	title = {On the {Analyses} of {Medical} {Images} {Using} {Traditional} {Machine} {Learning} {Techniques} and {Convolutional} {Neural} {Networks}},
	volume = {30},
	issn = {1134-3060, 1886-1784},
	url = {https://link.springer.com/10.1007/s11831-023-09899-9},
	doi = {10.1007/s11831-023-09899-9},
	abstract = {Abstract
            Convolutional neural network (CNN) has shown dissuasive accomplishment on different areas especially Object Detection, Segmentation, Reconstruction (2D and 3D), Information Retrieval, Medical Image Registration, Multi-lingual translation, Local language Processing, Anomaly Detection on video and Speech Recognition. CNN is a special type of Neural Network, which has compelling and effective learning ability to learn features at several steps during augmentation of the data. Recently, different interesting and inspiring ideas of Deep Learning (DL) such as different activation functions, hyperparameter optimization, regularization, momentum and loss functions has improved the performance, operation and execution of CNN Different internal architecture innovation of CNN and different representational style of CNN has significantly improved the performance. This survey focuses on internal taxonomy of deep learning, different models of vonvolutional neural network, especially depth and width of models and in addition CNN components, applications and current challenges of deep learning.},
	language = {en},
	number = {5},
	urldate = {2024-06-06},
	journal = {Archives of Computational Methods in Engineering},
	author = {Iqbal, Saeed and N. Qureshi, Adnan and Li, Jianqiang and Mahmood, Tariq},
	month = jun,
	year = {2023},
	pages = {3173--3233},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\H4PVV6LM\\Iqbal et al. - 2023 - On the Analyses of Medical Images Using Traditiona.pdf:application/pdf},
}

@misc{deng_fcn_2023,
	title = {{FCN}+: {Global} {Receptive} {Convolution} {Makes} {FCN} {Great} {Again}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{FCN}+},
	url = {https://arxiv.org/abs/2303.04589},
	doi = {10.48550/ARXIV.2303.04589},
	abstract = {Fully convolutional network (FCN) is a seminal work for semantic segmentation. However, due to its limited receptive field, FCN cannot effectively capture global context information which is vital for semantic segmentation. As a result, it is beaten by state-of-the-art methods which leverage different filter sizes for larger receptive fields. However, such a strategy usually introduces more parameters and increases the computational cost. In this paper, we propose a novel global receptive convolution (GRC) to effectively increase the receptive field of FCN for context information extraction, which results in an improved FCN termed FCN+. The GRC provides global receptive field for convolution without introducing any extra learnable parameters. The motivation of GRC is that different channels of a convolutional filter can have different grid sampling locations across the whole input feature map. Specifically, the GRC first divides the channels of the filter into two groups. The grid sampling locations of the first group are shifted to different spatial coordinates across the whole feature map, according to their channel indexes. This can help the convolutional filter capture the global context information. The grid sampling location of the second group remains unchanged to keep the original location information. Convolving using these two groups, the GRC can integrate the global context into the original location information of each pixel for better dense prediction results. With the GRC built in, FCN+ can achieve comparable performance to state-of-the-art methods for semantic segmentation tasks, as verified on PASCAL VOC 2012, Cityscapes, and ADE20K.},
	urldate = {2024-06-06},
	publisher = {arXiv},
	author = {Deng, Zhongying and Ren, Xiaoyu and Ye, Jin and He, Junjun and Qiao, Yu},
	year = {2023},
	note = {Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@misc{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {U-{Net}},
	url = {https://arxiv.org/abs/1505.04597},
	doi = {10.48550/ARXIV.1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2024-06-15},
	publisher = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	year = {2015},
	note = {Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@misc{williams_unified_2023,
	title = {A {Unified} {Framework} for {U}-{Net} {Design} and {Analysis}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2305.19638},
	doi = {10.48550/ARXIV.2305.19638},
	abstract = {U-Nets are a go-to, state-of-the-art neural architecture across numerous tasks for continuous signals on a square such as images and Partial Differential Equations (PDE), however their design and architecture is understudied. In this paper, we provide a framework for designing and analysing general U-Net architectures. We present theoretical results which characterise the role of the encoder and decoder in a U-Net, their high-resolution scaling limits and their conjugacy to ResNets via preconditioning. We propose Multi-ResNets, U-Nets with a simplified, wavelet-based encoder without learnable parameters. Further, we show how to design novel U-Net architectures which encode function constraints, natural bases, or the geometry of the data. In diffusion models, our framework enables us to identify that high-frequency information is dominated by noise exponentially faster, and show how U-Nets with average pooling exploit this. In our experiments, we demonstrate how Multi-ResNets achieve competitive and often superior performance compared to classical U-Nets in image segmentation, PDE surrogate modelling, and generative modelling with diffusion models. Our U-Net framework paves the way to study the theoretical properties of U-Nets and design natural, scalable neural architectures for a multitude of problems beyond the square.},
	urldate = {2024-06-15},
	publisher = {arXiv},
	author = {Williams, Christopher and Falck, Fabian and Deligiannidis, George and Holmes, Chris and Doucet, Arnaud and Syed, Saifuddin},
	year = {2023},
	note = {Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.IV), Machine Learning (cs.LG), Machine Learning (stat.ML)},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\PJ69I7DU\\Williams et al. - 2023 - A Unified Framework for U-Net Design and Analysis.pdf:application/pdf},
}

@article{siddique_u-net_2020,
	title = {U-{Net} and its variants for medical image segmentation: theory and applications},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {U-{Net} and its variants for medical image segmentation},
	url = {https://arxiv.org/abs/2011.01118},
	doi = {10.48550/ARXIV.2011.01118},
	abstract = {U-net is an image segmentation technique developed primarily for medical image analysis that can precisely segment images using a scarce amount of training data. These traits provide U-net with a very high utility within the medical imaging community and have resulted in extensive adoption of U-net as the primary tool for segmentation tasks in medical imaging. The success of U-net is evident in its widespread use in all major image modalities from CT scans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a segmentation tool, there have been instances of the use of U-net in other applications. As the potential of U-net is still increasing, in this review we look at the various developments that have been made in the U-net architecture and provide observations on recent trends. We examine the various innovations that have been made in deep learning and discuss how these tools facilitate U-net. Furthermore, we look at image modalities and application areas where U-net has been applied.},
	urldate = {2024-06-15},
	author = {Siddique, Nahian and Sidike, Paheding and Elkin, Colin and Devabhaktuni, Vijay},
	year = {2020},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.IV), Machine Learning (cs.LG)},
}

@article{younisse_fine-tuning_2023,
	title = {Fine-tuning {U}-net for medical image segmentation based on activation function, optimizer and pooling layer},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by-sa/4.0},
	issn = {2722-2578, 2088-8708},
	url = {https://ijece.iaescore.com/index.php/IJECE/article/view/30488},
	doi = {10.11591/ijece.v13i5.pp5406-5417},
	abstract = {{\textless}span lang="EN-US"{\textgreater}U-net convolutional neural network (CNN) is a famous architecture developed to deal with medical images. Fine-tuning CNNs is a common technique used to enhance their performance by selecting the building blocks which can provide the ultimate results. This paper introduces a method for tuning U-net architecture to improve its performance in medical image segmentation. The experiment is conducted using an x-ray image segmentation approach. The performance of U-net CNN in lung x-ray image segmentation is studied with different activation functions, optimizers, and pooling-bottleneck-layers. The analysis focuses on creating a method that can be applied for tuning U-net, like CNNs. It also provides the best activation function, optimizer, and pooling layer to enhance U-net CNN’s performance on x-ray image segmentation. The findings of this research showed that a U-net architecture worked supremely when we used the LeakyReLU activation function and average pooling layer as well as RMSProb optimizer. The U-net model accuracy is raised from 89.59 to 93.81\% when trained and tested with lung x-ray images and uses the LeakyReLU activation function, average pooling layer, and RMSProb optimizer. The fine-tuned model also enhanced accuracy results with three other datasets.{\textless}/span{\textgreater}},
	number = {5},
	urldate = {2024-06-15},
	journal = {International Journal of Electrical and Computer Engineering (IJECE)},
	author = {Younisse, Remah and Ghnemat, Rawan and Al Saraireh, Jaafer},
	month = oct,
	year = {2023},
	pages = {5406},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\9GXZZ6X9\\Younisse et al. - 2023 - Fine-tuning U-net for medical image segmentation b.pdf:application/pdf},
}

@article{conze_current_2023,
	title = {Current and {Emerging} {Trends} in {Medical} {Image} {Segmentation} {With} {Deep} {Learning}},
	volume = {7},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2469-7311, 2469-7303},
	url = {https://ieeexplore.ieee.org/document/10098158/},
	doi = {10.1109/TRPMS.2023.3265863},
	number = {6},
	urldate = {2024-06-15},
	journal = {IEEE Transactions on Radiation and Plasma Medical Sciences},
	author = {Conze, Pierre-Henri and Andrade-Miranda, Gustavo and Singh, Vivek Kumar and Jaouen, Vincent and Visvikis, Dimitris},
	month = jul,
	year = {2023},
	pages = {545--569},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\4PCXY6AD\\Conze et al. - 2023 - Current and Emerging Trends in Medical Image Segme.pdf:application/pdf},
}

@article{purushothaman_image_2022,
	title = {Image {Super}-{Resolution} using {Auto}-{Encoders} with {Parallel} {Skip}-{Connections}},
	volume = {18},
	issn = {1549-3636},
	url = {https://thescipub.com/abstract/10.3844/jcssp.2022.1051.1061},
	doi = {10.3844/jcssp.2022.1051.1061},
	number = {11},
	urldate = {2024-06-15},
	journal = {Journal of Computer Science},
	author = {Purushothaman, Lisha Pulickal and Kadangote, Jayasree Vadakke},
	month = nov,
	year = {2022},
	pages = {1051--1061},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\2RQU2S3N\\Purushothaman and Kadangote - 2022 - Image Super-Resolution using Auto-Encoders with Pa.pdf:application/pdf},
}

@misc{oktay_attention_2018,
	title = {Attention {U}-{Net}: {Learning} {Where} to {Look} for the {Pancreas}},
	shorttitle = {Attention {U}-{Net}},
	url = {http://arxiv.org/abs/1804.03999},
	abstract = {We propose a novel attention gate (AG) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes. Models trained with AGs implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a speciﬁc task. This enables us to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks (CNNs). AGs can be easily integrated into standard CNN architectures such as the U-Net model with minimal computational overhead while increasing the model sensitivity and prediction accuracy. The proposed Attention U-Net architecture is evaluated on two large CT abdominal datasets for multi-class image segmentation. Experimental results show that AGs consistently improve the prediction performance of U-Net across different datasets and training sizes while preserving computational efﬁciency. The code for the proposed architecture is publicly available.},
	language = {en},
	urldate = {2024-06-20},
	publisher = {arXiv},
	author = {Oktay, Ozan and Schlemper, Jo and Folgoc, Loic Le and Lee, Matthew and Heinrich, Mattias and Misawa, Kazunari and Mori, Kensaku and McDonagh, Steven and Hammerla, Nils Y. and Kainz, Bernhard and Glocker, Ben and Rueckert, Daniel},
	month = may,
	year = {2018},
	note = {arXiv:1804.03999 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Oktay et al. - 2018 - Attention U-Net Learning Where to Look for the Pa.pdf:C\:\\Users\\junpi\\Zotero\\storage\\KGB2IJEU\\Oktay et al. - 2018 - Attention U-Net Learning Where to Look for the Pa.pdf:application/pdf},
}

@misc{minaee_image_2020,
	title = {Image {Segmentation} {Using} {Deep} {Learning}: {A} {Survey}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Image {Segmentation} {Using} {Deep} {Learning}},
	url = {https://arxiv.org/abs/2001.05566},
	doi = {10.48550/ARXIV.2001.05566},
	abstract = {Image segmentation is a key topic in image processing and computer vision with applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among many others. Various algorithms for image segmentation have been developed in the literature. Recently, due to the success of deep learning models in a wide range of vision applications, there has been a substantial amount of works aimed at developing image segmentation approaches using deep learning models. In this survey, we provide a comprehensive review of the literature at the time of this writing, covering a broad spectrum of pioneering works for semantic and instance-level segmentation, including fully convolutional pixel-labeling networks, encoder-decoder architectures, multi-scale and pyramid based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the similarity, strengths and challenges of these deep learning models, examine the most widely used datasets, report performances, and discuss promising future research directions in this area.},
	urldate = {2024-06-20},
	publisher = {arXiv},
	author = {Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
	year = {2020},
	note = {Version Number: 5},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@misc{chiang_activation_2023,
	title = {Activation {Functions} {Not} {To} {Active}: {A} {Plausible} {Theory} on {Interpreting} {Neural} {Networks}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Activation {Functions} {Not} {To} {Active}},
	url = {https://arxiv.org/abs/2305.00663},
	doi = {10.48550/ARXIV.2305.00663},
	abstract = {Researchers commonly believe that neural networks model a high-dimensional space but cannot give a clear definition of this space. What is this space? What is its dimension? And does it has finite dimensions? In this paper, we develop a plausible theory on interpreting neural networks in terms of the role of activation functions in neural networks and define a high-dimensional (more precisely, an infinite-dimensional) space that neural networks including deep-learning networks could create. We show that the activation function acts as a magnifying function that maps the low-dimensional linear space into an infinite-dimensional space, which can distinctly identify the polynomial approximation of any multivariate continuous function of the variable values being the same features of the given dataset. Given a dataset with each example of \$d\$ features \$f\_1\$, \$f\_2\$, \${\textbackslash}cdots\$, \$f\_d\$, we believe that neural networks model a special space with infinite dimensions, each of which is a monomial \$\${\textbackslash}prod\_\{i\_1, i\_2, {\textbackslash}cdots, i\_d\} f\_1{\textasciicircum}\{i\_1\} f\_2{\textasciicircum}\{i\_2\} {\textbackslash}cdots f\_d{\textasciicircum}\{i\_d\}\$\$ for some non-negative integers \$\{i\_1, i\_2, {\textbackslash}cdots, i\_d\} {\textbackslash}in {\textbackslash}mathbb\{Z\}\_\{0\}{\textasciicircum}\{+\}={\textbackslash}\{0,1,2,3,{\textbackslash}ldots{\textbackslash}\} \$. We term such an infinite-dimensional space a \${\textbackslash}textit\{ Super Space (SS)\}\$. We see such a dimension as the minimum information unit. Every neuron node previously through an activation layer in neural networks is a \${\textbackslash}textit\{ Super Plane (SP) \}\$, which is actually a polynomial of infinite degree. This \${\textbackslash}textit\{ Super Space \}\$ is something like a coordinate system, in which every multivalue function can be represented by a \${\textbackslash}textit\{ Super Plane \}\$. We also show that training NNs could at least be reduced to solving a system of nonlinear equations. \%solve sets of nonlinear equations},
	urldate = {2024-06-20},
	publisher = {arXiv},
	author = {Chiang, John},
	year = {2023},
	note = {Version Number: 2},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE)},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\6VA9969I\\Chiang - 2023 - Activation Functions Not To Active A Plausible Th.pdf:application/pdf},
}

@article{jiang_iu-net_2023,
	title = {{iU}-{Net}: a hybrid structured network with a novel feature fusion approach for medical image segmentation},
	volume = {16},
	issn = {1756-0381},
	shorttitle = {{iU}-{Net}},
	url = {https://biodatamining.biomedcentral.com/articles/10.1186/s13040-023-00320-6},
	doi = {10.1186/s13040-023-00320-6},
	abstract = {Abstract
            In recent years, convolutional neural networks (CNNs) have made great achievements in the field of medical image segmentation, especially full convolutional neural networks based on U-shaped structures and skip connections. However, limited by the inherent limitations of convolution, CNNs-based methods usually exhibit limitations in modeling long-range dependencies and are unable to extract large amounts of global contextual information, which deprives neural networks of the ability to adapt to different visual modalities. In this paper, we propose our own model, which is called iU-Net bacause its structure closely resembles the combination of i and U. iU-Net is a multiple encoder-decoder structure combining Swin Transformer and CNN. We use a hierarchical Swin Transformer structure with shifted windows as the primary encoder and convolution as the secondary encoder to complement the context information extracted by the primary encoder. To sufficiently fuse the feature information extracted from multiple encoders, we design a feature fusion module (W-FFM) based on wave function representation. Besides, a three branch up sampling method(Tri-Upsample) has developed to replace the patch expand in the Swin Transformer, which can effectively avoid the Checkerboard Artifacts caused by the patch expand.
            On the skin lesion region segmentation task, the segmentation performance of iU-Net is optimal, with Dice and Iou reaching 90.12\% and 83.06\%, respectively. To verify the generalization of iU-Net, we used the model trained on ISIC2018 dataset to test on PH2 dataset, and achieved 93.80\% Dice and 88.74\% IoU. On the lung feild segmentation task, the iU-Net achieved optimal results on IoU and Precision, reaching 98.54\% and 94.35\% respectively. Extensive experiments demonstrate the segmentation performance and generalization ability of iU-Net.},
	language = {en},
	number = {1},
	urldate = {2024-06-20},
	journal = {BioData Mining},
	author = {Jiang, Yun and Dong, Jinkun and Cheng, Tongtong and Zhang, Yuan and Lin, Xin and Liang, Jing},
	month = feb,
	year = {2023},
	pages = {5},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\VDXQVNMM\\Jiang et al. - 2023 - iU-Net a hybrid structured network with a novel f.pdf:application/pdf},
}

@misc{howard_hubmap_2023,
	title = {{HuBMAP} - {Hacking} the {Human} {Vasculature}},
	publisher = {https://kaggle.com/competitions/hubmap-hacking-the-human-vasculature},
	author = {Howard, Addison and Jevster, HCL and Gustilo, Katherine and Börner, Katy and Holbrook, Ryan and Yashvardhan, Jain},
	year = {2023},
}

@article{guven_microcirculation_2020,
	title = {Microcirculation: {Physiology}, {Pathophysiology}, and {Clinical} {Application}},
	volume = {49},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {0253-5068, 1421-9735},
	shorttitle = {Microcirculation},
	url = {https://karger.com/BPU/article/doi/10.1159/000503775},
	doi = {10.1159/000503775},
	abstract = {This paper briefly reviews the physiological components of the microcirculation, focusing on its function in homeostasis and its central function in the realization of oxygen transport to tissue cells. Its pivotal role in the understanding of circulatory compromise in states of shock and renal compromise is discussed. Our introduction of hand-held vital microscopes (HVM) to clinical medicine has revealed the importance of the microcirculation as a central target organ in states of critical illness and inadequate response to therapy. Technical and methodological developments have been made in hardware and in software including our recent introduction and validation of automatic analysis software called MicroTools, which now allows point-of-care use of HVM imaging at the bedside for instant availability of functional microcirculatory parameters needed for microcirculatory targeted resuscitation procedures to be a reality.},
	language = {en},
	number = {1-2},
	urldate = {2024-06-21},
	journal = {Blood Purification},
	author = {Guven, Goksel and Hilty, Matthias P. and Ince, Can},
	year = {2020},
	pages = {143--150},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\2AW4PBWN\\Guven et al. - 2020 - Microcirculation Physiology, Pathophysiology, and.pdf:application/pdf},
}

@misc{long_fully_2014,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1411.4038},
	doi = {10.48550/ARXIV.1411.4038},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
	urldate = {2024-06-21},
	publisher = {arXiv},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2014},
	note = {Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@article{albelwi_framework_2017,
	title = {A {Framework} for {Designing} the {Architectures} of {Deep} {Convolutional} {Neural} {Networks}},
	volume = {19},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/19/6/242},
	doi = {10.3390/e19060242},
	abstract = {Recent advances in Convolutional Neural Networks (CNNs) have obtained promising results in difficult deep learning tasks. However, the success of a CNN depends on finding an architecture to fit a given problem. A hand-crafted architecture is a challenging, time-consuming process that requires expert knowledge and effort, due to a large number of architectural design choices. In this article, we present an efficient framework that automatically designs a high-performing CNN architecture for a given problem. In this framework, we introduce a new optimization objective function that combines the error rate and the information learnt by a set of feature maps using deconvolutional networks (deconvnet). The new objective function allows the hyperparameters of the CNN architecture to be optimized in a way that enhances the performance by guiding the CNN through better visualization of learnt features via deconvnet. The actual optimization of the objective function is carried out via the Nelder-Mead Method (NMM). Further, our new objective function results in much faster convergence towards a better architecture. The proposed framework has the ability to explore a CNN architecture’s numerous design choices in an efficient way and also allows effective, distributed execution and synchronization via web services. Empirically, we demonstrate that the CNN architecture designed with our approach outperforms several existing approaches in terms of its error rate. Our results are also competitive with state-of-the-art results on the MNIST dataset and perform reasonably against the state-of-the-art results on CIFAR-10 and CIFAR-100 datasets. Our approach has a significant role in increasing the depth, reducing the size of strides, and constraining some convolutional layers not followed by pooling layers in order to find a CNN architecture that produces a high recognition performance.},
	language = {en},
	number = {6},
	urldate = {2024-06-21},
	journal = {Entropy},
	author = {Albelwi, Saleh and Mahmood, Ausif},
	month = may,
	year = {2017},
	pages = {242},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\8HGIQMIP\\Albelwi and Mahmood - 2017 - A Framework for Designing the Architectures of Dee.pdf:application/pdf},
}

@incollection{pajankar_convolutional_2022,
	address = {Berkeley, CA},
	title = {Convolutional {Neural} {Networks}},
	isbn = {978-1-4842-7920-5 978-1-4842-7921-2},
	url = {https://link.springer.com/10.1007/978-1-4842-7921-2_14},
	language = {en},
	urldate = {2024-06-22},
	booktitle = {Hands-on {Machine} {Learning} with {Python}},
	publisher = {Apress},
	author = {Pajankar, Ashwin and Joshi, Aditya},
	collaborator = {Pajankar, Ashwin and Joshi, Aditya},
	year = {2022},
	doi = {10.1007/978-1-4842-7921-2_14},
	pages = {261--284},
}

@article{heaton_ian_2018,
	title = {Ian {Goodfellow}, {Yoshua} {Bengio}, and {Aaron} {Courville}: {Deep} learning: {The} {MIT} {Press}, 2016, 800 pp, {ISBN}: 0262035618},
	volume = {19},
	issn = {1389-2576, 1573-7632},
	shorttitle = {Ian {Goodfellow}, {Yoshua} {Bengio}, and {Aaron} {Courville}},
	url = {http://link.springer.com/10.1007/s10710-017-9314-z},
	doi = {10.1007/s10710-017-9314-z},
	language = {en},
	number = {1-2},
	urldate = {2024-06-22},
	journal = {Genetic Programming and Evolvable Machines},
	author = {Heaton, Jeff},
	month = jun,
	year = {2018},
	pages = {305--307},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\E5F3VLUB\\Heaton - 2018 - Ian Goodfellow, Yoshua Bengio, and Aaron Courville.pdf:application/pdf},
}

@book{klette_concise_2014,
	address = {London},
	series = {Undergraduate {Topics} in {Computer} {Science}},
	title = {Concise {Computer} {Vision}: {An} {Introduction} into {Theory} and {Algorithms}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-1-4471-6319-0 978-1-4471-6320-6},
	shorttitle = {Concise {Computer} {Vision}},
	url = {https://link.springer.com/10.1007/978-1-4471-6320-6},
	language = {en},
	urldate = {2024-06-22},
	publisher = {Springer London},
	author = {Klette, Reinhard},
	year = {2014},
	doi = {10.1007/978-1-4471-6320-6},
	file = {Submitted Version:C\:\\Users\\junpi\\Zotero\\storage\\YVMNVTQE\\Klette - 2014 - Concise Computer Vision An Introduction into Theo.pdf:application/pdf},
}

@book{bishop_deep_2024,
	address = {Cham},
	title = {Deep {Learning}: {Foundations} and {Concepts}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-45467-7 978-3-031-45468-4},
	shorttitle = {Deep {Learning}},
	url = {https://link.springer.com/10.1007/978-3-031-45468-4},
	language = {en},
	urldate = {2024-06-24},
	publisher = {Springer International Publishing},
	author = {Bishop, Christopher M. and Bishop, Hugh},
	year = {2024},
	doi = {10.1007/978-3-031-45468-4},
}

@book{pajankar_hands-machine_2022,
	address = {Berkeley, CA},
	title = {Hands-on {Machine} {Learning} with {Python}: {Implement} {Neural} {Network} {Solutions} with {Scikit}-learn and {PyTorch}},
	copyright = {https://www.springer.com/tdm},
	isbn = {978-1-4842-7920-5 978-1-4842-7921-2},
	shorttitle = {Hands-on {Machine} {Learning} with {Python}},
	url = {https://link.springer.com/10.1007/978-1-4842-7921-2},
	language = {en},
	urldate = {2024-06-27},
	publisher = {Apress},
	author = {Pajankar, Ashwin and Joshi, Aditya},
	year = {2022},
	doi = {10.1007/978-1-4842-7921-2},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\SPNBL7EL\\Pajankar and Joshi - 2022 - Hands-on Machine Learning with Python Implement N.pdf:application/pdf},
}

@book{sasaki_hands-machine_2019,
	address = {Birmingham, UK},
	title = {Hands-on machine learning with {TensorFlow}.js: a guide to building {ML} applications integrated with web technology using the {TensorFlow}.js library},
	isbn = {978-1-83882-787-8},
	shorttitle = {Hands-on machine learning with {TensorFlow}.js},
	language = {eng},
	publisher = {Packt Publishing},
	author = {Sasaki, Kai},
	year = {2019},
	note = {OCLC: 1154455651},
}

@misc{herrera_impact_2022,
	title = {Impact of loss function in {Deep} {Learning} methods for accurate retinal vessel segmentation},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2206.00536},
	doi = {10.48550/ARXIV.2206.00536},
	abstract = {The retinal vessel network studied through fundus images contributes to the diagnosis of multiple diseases not only found in the eye. The segmentation of this system may help the specialized task of analyzing these images by assisting in the quantification of morphological characteristics. Due to its relevance, several Deep Learning-based architectures have been tested for tackling this problem automatically. However, the impact of loss function selection on the segmentation of the intricate retinal blood vessel system hasn't been systematically evaluated. In this work, we present the comparison of the loss functions Binary Cross Entropy, Dice, Tversky, and Combo loss using the deep learning architectures (i.e. U-Net, Attention U-Net, and Nested UNet) with the DRIVE dataset. Their performance is assessed using four metrics: the AUC, the mean squared error, the dice score, and the Hausdorff distance. The models were trained with the same number of parameters and epochs. Using dice score and AUC, the best combination was SA-UNet with Combo loss, which had an average of 0.9442 and 0.809 respectively. The best average of Hausdorff distance and mean square error were obtained using the Nested U-Net with the Dice loss function, which had an average of 6.32 and 0.0241 respectively. The results showed that there is a significant difference in the selection of loss function},
	urldate = {2024-07-07},
	publisher = {arXiv},
	author = {Herrera, Daniela and Ochoa-Ruiz, Gilberto and Gonzalez-Mendoza, Miguel and Mata, Christian},
	year = {2022},
	note = {Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.IV)},
}

@book{dawani_hands-mathematics_2020,
	address = {Birmingham Mumbai},
	title = {Hands-on mathematics for deep learning: build a solid mathematical foundation for training efficient deep neural networks},
	isbn = {978-1-83864-729-2},
	shorttitle = {Hands-on mathematics for deep learning},
	language = {eng},
	publisher = {PACKT},
	author = {Dawani, Jay},
	year = {2020},
}

@incollection{bishop_backpropagation_2024,
	address = {Cham},
	title = {Backpropagation},
	isbn = {978-3-031-45467-7 978-3-031-45468-4},
	url = {https://link.springer.com/10.1007/978-3-031-45468-4_8},
	language = {en},
	urldate = {2024-07-09},
	booktitle = {Deep {Learning}},
	publisher = {Springer International Publishing},
	author = {Bishop, Christopher M. and Bishop, Hugh},
	collaborator = {Bishop, Christopher M. and Bishop, Hugh},
	year = {2024},
	doi = {10.1007/978-3-031-45468-4_8},
	pages = {233--252},
}

@misc{dumoulin_guide_2018,
	title = {A guide to convolution arithmetic for deep learning},
	url = {http://arxiv.org/abs/1603.07285},
	abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
	urldate = {2024-07-09},
	publisher = {arXiv},
	author = {Dumoulin, Vincent and Visin, Francesco},
	month = jan,
	year = {2018},
	note = {arXiv:1603.07285 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\junpi\\Zotero\\storage\\TV8AGTFM\\Dumoulin and Visin - 2018 - A guide to convolution arithmetic for deep learnin.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\junpi\\Zotero\\storage\\JP2GE2H8\\1603.html:text/html},
}

@inproceedings{zhao_attention-based_2023,
	address = {Xi'an, China},
	title = {Attention-based {Mask} {R}-{CNN} for {Microvascular} {Segmentation}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350382877},
	url = {https://ieeexplore.ieee.org/document/10490963/},
	doi = {10.1109/ICEMCE60359.2023.10490963},
	urldate = {2024-07-16},
	booktitle = {2023 7th {International} {Conference} on {Electrical}, {Mechanical} and {Computer} {Engineering} ({ICEMCE})},
	publisher = {IEEE},
	author = {Zhao, Henan and Yang, Zekai and Mo, Tong and Yao, Yiya},
	month = oct,
	year = {2023},
	pages = {961--966},
	file = {Zhang et al. - 2023 - Attention-based Mask R-CNN for Microvascular Segme.pdf:C\:\\Users\\junpi\\Zotero\\storage\\BPKPXGN5\\Zhang et al. - 2023 - Attention-based Mask R-CNN for Microvascular Segme.pdf:application/pdf},
}

@incollection{dubitzky_part--speech_2013,
	address = {New York, NY},
	title = {Part-of-{Speech} {Tagging}},
	isbn = {978-1-4419-9862-0 978-1-4419-9863-7},
	url = {http://link.springer.com/10.1007/978-1-4419-9863-7_162},
	language = {en},
	urldate = {2024-07-16},
	booktitle = {Encyclopedia of {Systems} {Biology}},
	publisher = {Springer New York},
	author = {Pyysalo, Sampo},
	editor = {Dubitzky, Werner and Wolkenhauer, Olaf and Cho, Kwang-Hyun and Yokota, Hiroki},
	year = {2013},
	doi = {10.1007/978-1-4419-9863-7_162},
	pages = {1650--1650},
}

@misc{muller_towards_2022,
	title = {Towards a {Guideline} for {Evaluation} {Metrics} in {Medical} {Image} {Segmentation}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2202.05273},
	doi = {10.48550/ARXIV.2202.05273},
	abstract = {In the last decade, research on artificial intelligence has seen rapid growth with deep learning models, especially in the field of medical image segmentation. Various studies demonstrated that these models have powerful prediction capabilities and achieved similar results as clinicians. However, recent studies revealed that the evaluation in image segmentation studies lacks reliable model performance assessment and showed statistical bias by incorrect metric implementation or usage. Thus, this work provides an overview and interpretation guide on the following metrics for medical image segmentation evaluation in binary as well as multi-class problems: Dice similarity coefficient, Jaccard, Sensitivity, Specificity, Rand index, ROC curves, Cohen's Kappa, and Hausdorff distance. As a summary, we propose a guideline for standardized medical image segmentation evaluation to improve evaluation quality, reproducibility, and comparability in the research field.},
	urldate = {2024-07-17},
	publisher = {arXiv},
	author = {Müller, Dominik and Soto-Rey, Iñaki and Kramer, Frank},
	year = {2022},
	note = {Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.IV), Machine Learning (cs.LG)},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\CG5ZARUD\\Müller et al. - 2022 - Towards a Guideline for Evaluation Metrics in Medi.pdf:application/pdf},
}

@misc{yu_hyper-parameter_2020,
	title = {Hyper-{Parameter} {Optimization}: {A} {Review} of {Algorithms} and {Applications}},
	shorttitle = {Hyper-{Parameter} {Optimization}},
	url = {http://arxiv.org/abs/2003.05689},
	abstract = {Since deep neural networks were developed, they have made huge contributions to everyday lives. Machine learning provides more rational advice than humans are capable of in almost every aspect of daily life. However, despite this achievement, the design and training of neural networks are still challenging and unpredictable procedures. To lower the technical thresholds for common users, automated hyper-parameter optimization (HPO) has become a popular topic in both academic and industrial areas. This paper provides a review of the most essential topics on HPO. The first section introduces the key hyper-parameters related to model training and structure, and discusses their importance and methods to define the value range. Then, the research focuses on major optimization algorithms and their applicability, covering their efficiency and accuracy especially for deep learning networks. This study next reviews major services and toolkits for HPO, comparing their support for state-of-the-art searching algorithms, feasibility with major deep learning frameworks, and extensibility for new modules designed by users. The paper concludes with problems that exist when HPO is applied to deep learning, a comparison between optimization algorithms, and prominent approaches for model evaluation with limited computational resources.},
	urldate = {2024-08-12},
	publisher = {arXiv},
	author = {Yu, Tong and Zhu, Hong},
	month = mar,
	year = {2020},
	note = {arXiv:2003.05689 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\junpi\\Zotero\\storage\\YSXKJC7G\\Yu and Zhu - 2020 - Hyper-Parameter Optimization A Review of Algorith.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\junpi\\Zotero\\storage\\7M7GGGDK\\2003.html:text/html},
}

@misc{wu_demystifying_2019,
	title = {Demystifying {Learning} {Rate} {Policies} for {High} {Accuracy} {Training} of {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1908.06477},
	abstract = {Learning Rate (LR) is an important hyper-parameter to tune for effective training of deep neural networks (DNNs). Even for the baseline of a constant learning rate, it is non-trivial to choose a good constant value for training a DNN. Dynamic learning rates involve multi-step tuning of LR values at various stages of the training process and offer high accuracy and fast convergence. However, they are much harder to tune. In this paper, we present a comprehensive study of 13 learning rate functions and their associated LR policies by examining their range parameters, step parameters, and value update parameters. We propose a set of metrics for evaluating and selecting LR policies, including the classification confidence, variance, cost, and robustness, and implement them in LRBench, an LR benchmarking system. LRBench can assist end-users and DNN developers to select good LR policies and avoid bad LR policies for training their DNNs. We tested LRBench on Caffe, an open source deep learning framework, to showcase the tuning optimization of LR policies. Evaluated through extensive experiments, we attempt to demystify the tuning of LR policies by identifying good LR policies with effective LR value ranges and step sizes for LR update schedules.},
	urldate = {2024-08-12},
	publisher = {arXiv},
	author = {Wu, Yanzhao and Liu, Ling and Bae, Juhyun and Chow, Ka-Ho and Iyengar, Arun and Pu, Calton and Wei, Wenqi and Yu, Lei and Zhang, Qi},
	month = oct,
	year = {2019},
	note = {arXiv:1908.06477 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\junpi\\Zotero\\storage\\NF7XRN3R\\Wu et al. - 2019 - Demystifying Learning Rate Policies for High Accur.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\junpi\\Zotero\\storage\\QBNSDR3N\\1908.html:text/html},
}

@incollection{thakur_exploring_2023,
	address = {Singapore},
	title = {Exploring the {Relationship} {Between} {Learning} {Rate}, {Batch} {Size}, and {Epochs} in {Deep} {Learning}: {An} {Experimental} {Study}},
	volume = {547},
	isbn = {978-981-19652-4-1 978-981-19652-5-8},
	shorttitle = {Exploring the {Relationship} {Between} {Learning} {Rate}, {Batch} {Size}, and {Epochs} in {Deep} {Learning}},
	url = {https://link.springer.com/10.1007/978-981-19-6525-8_16},
	language = {en},
	urldate = {2024-08-12},
	booktitle = {Soft {Computing} for {Problem} {Solving}},
	publisher = {Springer Nature Singapore},
	author = {Shafi, Sadaf and Assad, Assif},
	editor = {Thakur, Manoj and Agnihotri, Samar and Rajpurohit, Bharat Singh and Pant, Millie and Deep, Kusum and Nagar, Atulya K.},
	year = {2023},
	doi = {10.1007/978-981-19-6525-8_16},
	note = {Series Title: Lecture Notes in Networks and Systems},
	pages = {201--209},
}

@misc{devarakonda_adabatch_2017,
	title = {{AdaBatch}: {Adaptive} {Batch} {Sizes} for {Training} {Deep} {Neural} {Networks}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{AdaBatch}},
	url = {https://arxiv.org/abs/1712.02029},
	doi = {10.48550/ARXIV.1712.02029},
	abstract = {Training deep neural networks with Stochastic Gradient Descent, or its variants, requires careful choice of both learning rate and batch size. While smaller batch sizes generally converge in fewer training epochs, larger batch sizes offer more parallelism and hence better computational efficiency. We have developed a new training approach that, rather than statically choosing a single batch size for all epochs, adaptively increases the batch size during the training process. Our method delivers the convergence rate of small batch sizes while achieving performance similar to large batch sizes. We analyse our approach using the standard AlexNet, ResNet, and VGG networks operating on the popular CIFAR-10, CIFAR-100, and ImageNet datasets. Our results demonstrate that learning with adaptive batch sizes can improve performance by factors of up to 6.25 on 4 NVIDIA Tesla P100 GPUs while changing accuracy by less than 1\% relative to training with fixed batch sizes.},
	urldate = {2024-08-13},
	publisher = {arXiv},
	author = {Devarakonda, Aditya and Naumov, Maxim and Garland, Michael},
	year = {2017},
	note = {Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, Machine Learning (cs.LG), Machine Learning (stat.ML), 68T05,, Distributed, Parallel, and Cluster Computing (cs.DC), I.2.6; I.5.0},
	file = {Full Text:C\:\\Users\\junpi\\Zotero\\storage\\FXFFE434\\Devarakonda et al. - 2017 - AdaBatch Adaptive Batch Sizes for Training Deep N.pdf:application/pdf},
}

@article{bria_addressing_2020,
	title = {Addressing class imbalance in deep learning for small lesion detection on medical images},
	volume = {120},
	issn = {00104825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482520301177},
	doi = {10.1016/j.compbiomed.2020.103735},
	language = {en},
	urldate = {2024-11-13},
	journal = {Computers in Biology and Medicine},
	author = {Bria, Alessandro and Marrocco, Claudio and Tortorella, Francesco},
	month = may,
	year = {2020},
	pages = {103735},
}
