\chapter{HASIL DAN PEMBAHASAN}

\section{Hasil Exploratory Data Analysis}
\label{sec:hasil-eda}

\noindent Tahap Exploratory Data Analysis (EDA) dilakukan untuk memahami karakteristik dataset citra jaringan ginjal secara mendalam. Tujuan utama EDA adalah untuk mengidentifikasi distribusi kelas, mengidentifikasi ketidakseimbangan kelas, dan menemukan pola-pola yang mungkin mempengaruhi kinerja model. Informasi yang diperoleh dari EDA akan digunakan menentukan teknik preprocessing yang tepat pada data sehingga model yang dilatih dapat memberikan hasil yang optimal.

\subsection{Distribusi Citra dalam Dataset}
\noindent Dari 7033 data yang disediakan oleh \textit{Human BioMolecular Atlas Program }(HuBMAP) terdapat 1633 citra jaringan ginjal manusia yang telah dilabeli dalam penelitian ini. Citra-citra tersebut terbagi menjadi dua dataset utama. Dataset pertama terdiri dari 2 sumber Whole Slide Imaging (WSI) yang berbeda, sedangkan dataset kedua berasal dari 4 sumber WSI yang berbeda. Diagram di bawah menunjukkan distribusi jumlah citra pada setiap dataset dan kombinasi dataset-sumber WSI.


\noindent Seperti yang terlihat pada Gambar \ref{fig:d_dataset}, dataset pertama memiliki jumlah citra yang lebih banyak dibandingkan dataset kedua. Sebaran citra pada masing-masing sumber WSI dalam kedua dataset cukup merata setelah ditampilkan berdasarkan asal sumbernya. Selanjutnya, observasi dilakukan untuk menganalisis karakteristik pembuluh darah dari masing-masing sumber WSI pada dataset 1 dan dataset 2 yang bisa dilihat pada lampiran \ref{sec:sample_gambar} Sample Gambar dari Setiap Sumber Whole Slide Image.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{gambar/bab4/dataset.png}
		\caption{Sebaran citra dalam dataset}
		\label{fig:d_dataset}
	\end{subfigure}
	\hspace{0.05\textwidth}
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{gambar/bab4/dataset_wsi.png}
		\caption{Sebaran citra dalam sumber WSI}
		\label{fig:d_WSI}
	\end{subfigure}	
	\caption{Sebaran citra pada tiap dataset dan sumber WSI}
	\label{fig:diagram_sebaran}
\end{figure}

\noindent Hasil observasi menunjukkan adanya perbedaan karakteristik pembuluh darah pada dataset 1 yang berasal dari source 1 dan source 2. Pembuluh darah pada source 1 cenderung berjumlah sedikit namun memiliki ukuran yang besar, sedangkan pada source 2, pembuluh darah lebih banyak tetapi berukuran kecil. Sebaliknya, pada dataset 2 yang berasal dari source 1 hingga source 4, tidak ditemukan karakteristik tertentu yang konsisten, karena setiap sampel menunjukkan variasi pembuluh darah yang sangat beragam.

\subsection{Ekplorasi Ukuran Piksel dan Kuantitas Pembuluh Darah}

\noindent Selanjutnya, distribusi ukuran rata-rata piksel pembuluh darah (dalam ribuan piksel) dan jumlah pembuluh darahuntuk setiap sumber dataset dapat dilihat pada Gambar \ref{fig:sct_1} dan \ref{fig:sct_2}. Scatter plot ini menunjukkan pola distribusi yang berbeda di antara sumber-sumber dataset. Pada dataset 1, sebagaimana terlihat pada Gambar \ref{fig:sct_1}, sumber 1 dan 2 memiliki jumlah pembuluh darah yang umumnya berkisar antara 0 hingga 30, dengan ukuran rata-rata piksel pembuluh darah yang cenderung kecil (<5 ribu piksel). Namun, sumber 1 memiliki jumlah pembuluh darah yang lebih sedikit tetapi dengan ukuran rata-rata piksel yang lebih besar dibandingkan sumber 2. Sementara itu, distribusi pada dataset 2 yang ditampilkan pada Gambar \ref{fig:sct_2} menunjukkan pola yang lebih beragam dibandingkan dataset 1. Ukuran rata-rata pembuluh darah pada sumber 1 hingga 4 umumnya lebih kecil, dengan sebagian besar pembuluh darah memiliki ukuran kurang dari 5 ribu piksel.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{gambar/bab4/sct_1.png}
	\caption{Sebaran ukuran dan kuantitas pembuluh darah dataset 1}
	\label{fig:sct_1}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{gambar/bab4/sct_2.png}
	\caption{Sebaran ukuran dan kuantitas pembuluh darah dataset 2}
	\label{fig:sct_2}
\end{figure}


\subsection{Distribusi label pada dataset}
\noindent Berdasarkan analisis terhadap keseluruhan label dalam dataset, hanya sekitar 5$\%$ label yang merepresentasikan object (pembuluh darah), sedangkan sisanya merupakan latar belakang. Distribusi rata-rata rasio label positif (pembuluh darah) terhadap total label untuk setiap sumber WSI dirangkum pada Tabel \ref{tab:distribusi_label} yang terlihat bahwa distribusi rasio label positif bervariasi antara dataset dan sumber WSI. Dataset 1 memiliki rasio rata-rata label positif yang lebih tinggi (sekitar 8$\%$) dibandingkan dengan dataset 2, di mana rata-rata rasio label positif berkisar antara 2$\%$ hingga 5$\%$. Hal ini menunjukkan adanya ketidakseimbangan kelas yang signifikan dalam dataset, dengan mayoritas piksel pada citra merupakan latar belakang.

\begin{table}[H]
	\centering
	\caption{Distribusi rata-rata rasio label positif pada setiap source WSI.}
	\label{tab:distribusi_label}
	\begin{tabular}{cll}
		\hline
		\multicolumn{1}{l}{Dataset} & Sumber WSI & Rasio Positif \\ \hline
		\multirow{2}{*}{1}          & 1          & 0.083776      \\
		& 2          & 0.084165       \\ \hline
		\multirow{4}{*}{2}          & 1          & 0.024374       \\
		& 2          & 0.048241       \\
		& 3          & 0.047921       \\
		& 4          & 0.023660       \\ \hline
	\end{tabular}
\end{table}


\section{Hasil Pelatihan dan Evaluasi}
\noindent Setelah memahami karakteristik dataset melalui Ekplolatory Data Analisys (EDA), model dilatih menggunakan konfigurasi praprosessing dan hyperparameter yang telah ditentukan di Bab \ref{sec:metode-penelitian} Metode Penelitian. Bagian ini akan menyajikan hasil training dan evaluasi model Attention U-Net serta pembandingnya, U-Net, untuk tugas segmentasi mikrovaskular ginjal. Pada tabel \ref{tab:training-results} disajikan seluruh metrik hasil pelatihan.



%\subsection{Hasil Plot Loss Pelatihan}

%\noindent Subbab ini membahas konfigurasi terbaik yang diperoleh pada model Attention U-Net tanpa penggunaan teknik oversampling. Konfigurasi terbaik dipilih berdasarkan nilai train loss dan test loss terendah, serta pola penurunan loss yang stabil selama pelatihan.

%\noindent Berdasarkan hasil eksperimen pada tabel \ref{tab:training-results}, konfigurasi terbaik diperoleh dengan optimizer Adam dan batch size 4, yang menghasilkan train loss sebesar 0.530 dan validation loss sebesar 0.554. Hal ini menunjukkan bahwa konfigurasi ini lebih stabil dibandingkan konfigurasi lain, sebagaimana ditunjukkan pada Gambar \ref{fig:loss_attention_terbaik}. Gambar tersebut juga menunjukkan bahwa training loss mengalami penurunan konsisten hingga mencapai konvergensi pada epoch ke-27 dengan learning rate sebesar 1.6e-6. Pola serupa terlihat pada validation loss, meskipun terdapat sedikit fluktuasi di epoch awal. Selama pelatihan tidak ditemukan indikasi overfitting, karena selisih antara training loss dan validation loss tetap kecil. Penggunaan early stopping membantu menghentikan pelatihan sebelum overfitting terjadi, sehingga validasi tetap konsisten.

%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=.8]{gambar/bab4/loss_adam_attention_u-net_4.png}
%	\caption{Penurunan training loss dan validation loss pada konfigurasi Attention U-Net terbaik (optimizer Adam, batch size 4).}
%	\label{fig:loss_attention_terbaik}
%\end{figure}

%\noindent Sebagai perbandingan, konfigurasi dengan optimizer SGD dan batch size 4 menghasilkan train loss sebesar 0.803 dan validation loss sebesar 0.817. Nilai ini lebih tinggi dibandingkan konfigurasi terbaik, menunjukkan bahwa optimizer Adam mampu memberikan stabilitas yang lebih baik dibandingkan SGD. Stabilitas ini didukung oleh kemampuan Adam dalam mengatur gradien selama proses pelatihan \cite{younisse_fine-tuning_2023}.

\subsection{Hasil Plot Loss Pelatihan}

Pada bagian ini, akan dibahas hasil eksperimen untuk mengevaluasi pelatihan model Attention U-Net dalam segmentasi mikrovaskular ginjal manusia. Analisis dilakukan dengan membandingkan penurunan loss selama pelatihan dan validasi, serta stabilitas model menggunakan berbagai konfigurasi optimizer dan batch size.

Seperti yang dilihat pada gambar \ref{fig:plot_train_adam}, optimizer adam memiliki fluktuasi yang lebih signifikan diawal pelatihan. Hal ini disebabkan oleh gradient awal pelatihan yang belum stabil sehingga mekanisme penyesuaian momen yang dilakukan oleh adam tidak bekerja dengan baik di awal pelatihan. Sebaliknya pada gambar \ref{fig:plot_train_sgd}, konfigurasi SGD menunjukkan penurunan loss yang lebih stabil di awal pelatihan. Hal ini dikarenakan SGD menggunakan learning rate yang tetap tanpa penyesuaian adaptif, sehingga gradien berubah secara lebih terkontrol. Namun, pola ini membuat SGD sedikit lebih lambat dalam mencapai penurunan loss yang signifikan dibandingkan Adam. Loss pelatihan Adam mendekati nilai minimum relatif lebih awal dibandingkan SGD. Setelah mencapai kestabilan, loss test pada konfigurasi Adam menunjukkan pola yang lebih halus dibandingkan SGD (Gambar \ref{fig:plot_train_adam} vs Gambar \ref{fig:plot_train_sgd}). Hal ini mengindikasikan bahwa Adam mampu menyesuaikan parameter dengan lebih baik pada tahap akhir pelatihan. Secara keseluruhan konfigurasi yang memberikan nilai loss paling minimum adalah optimizer adam dengan batch size 4 dengan nilai sebesar 0.53 pada loss data latih dan 0.55 pada loss data test.

Secara keseluruhan, konfigurasi optimizer Adam dengan batch size 4 menunjukkan performa terbaik dalam menghasilkan nilai loss minimum baik pada data latih maupun data test. Hasil ini menunjukkan bahwa penggunaan optimizer adaptif seperti Adam, dikombinasikan dengan batch size kecil, memberikan kecepatan konvergensi yang tinggi dan stabilitas pada tahap akhir pelatihan, yang sangat penting untuk segmentasi mikrovaskular ginjal manusia.


\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{gambar/bab4/loss_adam.png}
	\caption{Plot loss pelatihan pada konfigurasi adam}
	\label{fig:plot_train_adam}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{gambar/bab4/loss_sgd.png}
	\caption{Plot loss pelatihan pada konfigurasi SGD}
	\label{fig:plot_train_sgd}
\end{figure}

\subsection{Evaluasi Kinerja Model dalam Segementasi}

\noindent Subbab ini mengevaluasi kinerja model Attention U-Net dan U-Net berdasarkan metrik utama, yaitu \textit{Dice Similarity Coefficient} (DSC). Evaluasi dilakukan untuk berbagai konfigurasi, termasuk variasi batch size dan optimizer, dengan tujuan mengidentifikasi konfigurasi terbaik untuk setiap arsitektur. 
%Tabel \ref{tab:training-results} menyajikan hasil lengkap dari semua eksperimen, di mana performa terbaik ditandai dengan cetak tebal untuk memudahkan interpretasi.

\noindent Berdasarkan hasil pada Tabel \ref{tab:training-results}, model Attention U-Net secara konsisten menunjukkan performa yang lebih baik dibandingkan U-Net pada semua metrik utama. Konfigurasi terbaik untuk Attention U-Net menggunakan optimizer Adam dan batch size 4 menghasilkan DSC sebesar 0.560 dan IoU sebesar 0.413. Sebagai perbandingan, konfigurasi terbaik untuk U-Net (optimizer Adam, batch size 4) hanya mencapai DSC sebesar 0.545 dan IoU sebesar 0.398. Perbedaan ini mengindikasikan bahwa penambahan mekanisme attention gate pada U-Net berkontribusi dalam meningkatkan kemampuan segmentasi.

%\noindent Selain itu perbedaan kinerja juga terlihat pada precission dan recal. Attention U-net precission lebih tinggi dibandingkan dengan U-net (0.675 vs 0.660 pada U-net), menunjukkan bahwa model ini lebih baik dalam menghindari false positive. Kemudian, recall pada Attention U-net juga lebih sedikit lebih tinggi dibandingkan dengan U-net (0.527 vs 0.510 pada U-net) menunjukkan kemampuan Attention U-net yang lebih baik dalam mendeteksi pembuluh darah kecil.

\noindent Hasil ini mendukung hipotesis bahwa Attention U-Net lebih unggul dalam tugas segmentasi mikrovaskular ginjal dibandingkan U-Net. Mekanisme attention gate membantu model memfokuskan pada area yang relevan, sehingga meningkatkan akurasi segmentasi secara keseluruhan \cite{oktay_attention_2018}. Dengan DSC mencapai 0.560 pada konfigurasi terbaik, model Attention U-Net menunjukkan kemampuan yang dapat diandalkan untuk tugas segmentasi mikrovaskular pada Whole Slide Images (WSI) jaringan ginjal manusia. Selain itu, hasil ini juga menyoroti pengaruh signifikan penambahan modul attention gate dalam meningkatkan kinerja U-Net, sejalan dengan tujuan penelitian ini.


\subsection{Dampak Oversampling pada Peforma Model}


\noindent Berdasarkan pembahasan yang telah di jabarkan sebelumnya jumlah citra yang telah di anotasi hanya berjumlah 1633 buah. Ukuran dataset ini terbilang kecil untuk tugas segmentasi mikrovaskular yang memiliki bentuk beragam. Untuk mengatasi masalah tersebut, dilakukan teknik \textit{patch-level oversampling} dikombinasikan dengan augmentasi pada dataset pelatihan, yang bertujuan meningkatkan jumlah sampel dari gambar unik. Tabel \ref{tab:training-results} menunjukkan bahwa oversampling memiliki dampak signifikan terhadap beberapa metrik utama, termasuk DSC (dari 0.560 menjadi 0.624) dan IoU (dari 0.413 menjadi 0.481). Peningkatan metrik ini menunjukkan bahwa oversampling meningkatkan exposure model terhadap variasi pembuluh darah sehingga lebih akurat dalam memetakan struktur pembuluh darah. 

%\noindent Peningkatan metrik ini menunjukkan bahwa oversampling membantu model untuk lebih akurat dalam memetakan struktur pembuluh darah, meskipun jumlah piksel pembuluh darah jauh lebih sedikit dibandingkan latar belakang. Peningkatan recall (dari 0.527 menjadi 0.595) juga mengindikasikan bahwa oversampling meningkatkan kemampuan model dalam mendeteksi pembuluh darah kecil. Kemudian, oversampling juga sedikit meningkatkan nilai precision (dari 0.674 menjadi 0.714), meskipun peningkatan ini relatif lebih kecil dibandingkan recall. Hal ini menunjukkan bahwa oversampling dapat memperbaiki ketidakseimbangan kelas tanpa meningkatkan jumlah false positive secara signifikan.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}

\subsection{Mengapa Batch Size Lebih Besar Tidak Selalu Meningkatkan Kinerja Attention U‑Net pada Segmentasi Mikrovaskular Ginjal Manusia?}

Pada Tabel \ref{tab:training-results} hasil eksperimen menunjukkan bahwa peningkatan batch size tidak selalu meningkatkan performa model. Hal ini berlawanan dengan ekspektasi umum, di mana peningkatan batch size diasumsikan akan meningkatkan performa model. Pada konfigurasi SGD, peningkatan batch size dari 4 ke 16 menyebabkan penurunan DSC sebesar 49{,}7\%, sementara pada Adam, fluktuasi performa relatif stabil (±1\%). Anomali ini dapat dijelaskan melalui interaksi antara \textit{batch size}, \textit{optimizer}, \textit{learning rate}, dan prinsip \textit{diminishing returns}.

\begin{enumerate}
	\item \textbf{Peran Optimizer dalam Respons terhadap Batch Size}
	\begin{itemize}
		\item \textbf{SGD (Stochastic Gradient Descent)}: Penurunan performa yang tajam pada SGD terjadi karena ketidaksesuaian antara \textit{batch size} dan \textit{learning rate}. Teori \textit{linear scaling rule} menyatakan bahwa peningkatan batch size harus diikuti peningkatan learning rate secara proporsional  \cite{goyal_accurate_2018, panda_new_2024}. Namun, dalam penelitian ini, learning rate diatur oleh \textit{ReduceLROnPlateau}, yang cenderung menurunkan learning rate saat loss stagnan. Akibatnya, update gradien pada batch size besar menjadi terlalu kecil, menyebabkan konvergensi tidak optimal. Contoh nyata terlihat pada DSC yang turun drastis dari 0{,}362 (batch size 4) ke 0{,}181 (batch size 16).
		
		\item \textbf{Adam (Adaptive Moment Estimation)}: Adam menunjukkan stabilitas yang lebih baik (±1\% penurunan DSC) berkat mekanisme \textit{adaptive learning rate} yang menyesuaikan nilai learning rate untuk setiap parameter. Hal ini memungkinkan model tetap konvergen meskipun batch size meningkat. Sebagai contoh, pada batch size 16 tanpa \textit{oversample}, DSC hanya turun 0{,}004 (0{,}556 → 0{,}552).
	\end{itemize}
	
	\item \textbf{Prinsip \textit{Diminishing Returns} pada Estimasi Gradien}
	
	Berdasarkan prinsip \textit{diminishing returns} pada estimasi gradien, peningkatan batch size hanya mengurangi error estimasi gradien secara proporsional dengan $1/\sqrt{N}$ \cite{bishop_deep_2024}. Artinya, peningkatan batch size dari 4 ke 16 hanya mengurangi \textit{noise} gradien sebesar 50\%, tetapi dalam eksperimen ini justru menurunkan performa model (DSC turun 1–10\%). Hal ini menunjukkan bahwa setelah batas tertentu, peningkatan batch size tidak lagi memberikan manfaat signifikan, bahkan dapat merugikan akibat hilangnya regularisasi implisit dari \textit{noise} gradien atau ketidaksesuaian learning rate.
\end{enumerate}



\begin{table}[H]
	\caption{Hasil pelatihan model Attention U-Net dan U-Net dengan berbagai konfigurasi hyperparameter}
	\label{tab:training-results}
	\begin{tabular}{llllll}
		\hline
		Model                             & Optimizer             & Batch Size & Oversample & DSC            & IoU            \\ \hline
		\multirow{10}{*}{Attention U-net} & \multirow{5}{*}{SGD}  & 4          & Tidak      & 0.362          & 0.239          \\
		&                       & 8          & Tidak      & 0.265          & 0.168          \\
		&                       & 16         & Tidak      & 0.181          & 0.113          \\ \cline{3-6} 
		&                       & 4          & Ya         & 0.506          & 0.363          \\
		&                       & 8          & Ya         & 0.478          & 0.337          \\ \cline{2-6} 
		& \multirow{5}{*}{Adam} & 4          & Tidak      & \textbf{0.56}  & \textbf{0.413} \\
		&                       & 8          & Tidak      & 0.546          & 0.34           \\
		&                       & 16         & Tidak      & 0.556          & 0.409          \\ \cline{3-6} 
		&                       & 4          & Ya         & \textbf{0.624} & \textbf{0.481} \\
		&                       & 8          & Ya         & 0.617          & 0.473          \\ \hline
		\multirow{10}{*}{U-net}           & \multirow{5}{*}{SGD}  & 4          & Tidak      & 0.521          & 0.375          \\
		&                       & 8          & Tidak      & 0.396          & 0.268          \\
		&                       & 16         & Tidak      & 0.425          & 0.29           \\ \cline{3-6} 
		&                       & 4          & Ya         & 0.521          & 0.376          \\
		&                       & 8          & Ya         & 0.510          & 0.367          \\ \cline{2-6} 
		& \multirow{5}{*}{Adam} & 4          & Tidak      & \textbf{0.545} & \textbf{0.398} \\
		&                       & 8          & Tidak      & 0.54           & 0.396          \\
		&                       & 16         & Tidak      & 0.544          & 0.397          \\ \cline{3-6} 
		&                       & 4          & Ya         & \textbf{0.616} & \textbf{0.472} \\
		&                       & 8          & Ya         & 0.612          & 0.467          \\ \hline
	\end{tabular}
\end{table}

\section{Hasil Segmentasi Mikrovaskular}

\noindent Berdasarkan evaluasi kuantitatif pada subbab sebelumnya, model Attention U-Net menunjukkan performa yang lebih unggul dibandingkan U-Net dalam tugas segmentasi mikrovaskular ginjal, dengan peningkatan pada metrik utama seperti Dice Similarity Coefficient (DSC), Intersection over Union (IoU), precision, dan recall. Nilai DSC sebesar 0.624 menunjukkan kemampuan model yang moderat dalam mendeteksi area pembuluh darah yang hampir sesuai dengan ground truth. Sementara itu, nilai IoU sebesar 0.413 mengindikasikan adanya tantangan dalam segmentasi, terutama karena tingginya jumlah false negative pada pembuluh darah besar.


\noindent Gambar \ref{fig:sample_hasil} menunjukkan hasil segmentasi dari model Attention U-Net dibandingkan dengan ground truth. Pada panel (d), area hijau yang signifikan (false negative) terlihat pada pembuluh darah besar, menunjukkan bahwa model sering gagal mendeteksi struktur ini. Sebaliknya, area kuning (true positive) mendominasi pada pembuluh darah kecil, mencerminkan kekuatan model dalam mendeteksi struktur kecil dan terdistribusi secara lokal.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.24\textwidth}
		\centering
		\includegraphics[width=\textwidth]{gambar/bab4/image_hasil.png}
		\caption{Citra test}
		\label{fig:image_hasil}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.24\textwidth}
		\centering
		\includegraphics[width=\textwidth]{gambar/bab4/true_label.png}
		\caption{label ground truth}
		\label{fig:true_label}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.24\textwidth}
		\centering
		\includegraphics[width=\textwidth]{gambar/bab4/predicted_label.png}
		\caption{Prediksi model}
		\label{fig:predicted_label}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.24\textwidth}
		\centering
		\includegraphics[width=\textwidth]{gambar/bab4/overlayed_label.png}
		\caption{Perbandingan}
		\label{fig:overlayed-label}
	\end{subfigure}
	
	\caption{Sample hasil segmentasi pada data test }
	\label{fig:sample_hasil}
	
\end{figure}

\noindent Hasil evaluasi ini menunjukkan bahwa kekuatan utama model Attention U-Net terletak pada kemampuannya mendeteksi pembuluh darah kecil, yang kemungkinan disebabkan oleh mekanisme perhatian (\textit{attention mechanism}) yang membantu fokus pada detail halus. Namun, tantangan terbesar model adalah mendeteksi pembuluh darah besar, yang mungkin disebabkan oleh kurangnya pembuluh darah berukuran besar berdasarkan temuan pada tahap eksplorasi data dimana data yang konsisten berukuran besar hanya ada pada dataset pertama sumber WSI pertama.





%\begin{table}[H]
%\centering
%\caption{Parameter kelulusan tugas akhir}
%\begin{tabular}{ clc }
%\hline
%\textbf{No.} & \textbf{Parameter } & \textbf{Nilai} \\
%\hline
%1. & Penulisan & A \\
%2. & Penulisan & A \\
%\hline
%\end{tabular}
%\label{table:nilai}
%\end{table}





% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}

%Berikut adalah contoh tabel yang dicetak secara horizontal
%gunakan package longtable
%Dapat dibuat dulu di https://www.tablesgenerator.com/ lalu dipindah
%\begin{landscape}
%\begin{longtable}{p{3.5cm}cllllll}
%\caption{Contoh Tabel Mendatar yang Panjang dan Lebar}\\
%\hline
%\textbf{Provinsi} & \textbf{Kode Wilayah} & \textbf{Singkatan Umum} & \textbf{ISO} & \textbf{Pulau} & \textbf{Ibu Kota} & \textbf{Gubernur} \\ \hline
%\endfirsthead

%\multicolumn{4}{l}{\bfseries \tablename\ \thetable{} -- Lanjutan dari halaman sebelumnya}\\
% \begin{center}
% % {{\bfseries \tablename\ \thetable{} -- Lanjutan dari halaman sebelumnya}} \\
% \end{center}
%\hline
%\textbf{Provinsi} & \textbf{Kode Wilayah} & \textbf{Singkatan Umum} & \textbf{ISO} & \textbf{Pulau} & \textbf{Ibu Kota} & \textbf{Gubernur} \\ \hline

%\endhead

%\hline
%\endfoot

%\endlastfoot



%Aceh & 11 & Aceh & ID-AC & Sumatera & Banda Aceh & Achmad Marzuki \\
%Sumatera Utara & 12 & Sumut & ID-SU & Sumatera & Medan & Edy Rahmayadi \\
%Sumatera Barat & 13 & Sumbar & ID-SB & Sumatera & Padang & Mahyeldi Ansharullah \\
%Riau & 14 & Riau & ID-RI & Sumatera & Pekanbaru & Syamsuar \\
%Jambi & 15 & Jambi & ID-JA & Sumatera & Jambi & Al Haris \\
%Sumatera Selatan & 16 & Sumsel & ID-SS & Sumatera & Palembang & Herman Deru \\
%Bengkulu & 17 & Bengkulu & ID-BE & Sumatera & Bengkulu & Rohidin Mersyah \\
%Lampung & 18 & Lampung & ID-LA & Sumatera & Bandar Lampung & Arinal Djunaidi \\
%Kepulauan Bangka Belitung & 19 & Babel & ID-BB & Sumatera & Pangkalpinang & Ridwan Djamaluddin \\
%Kepulauan Riau & 21 & Kepri & ID-KR & Sumatera & Tanjungpinang & Ansar Ahmad \\
%Daerah Khusus Ibukota Jakarta & 31 & DKI Jakarta & ID-JK & Jawa & Tidak ada & Heru Budi Hartono \\
%Jawa Barat & 32 & Jabar & ID-JB & Jawa & Bandung & Ridwan Kamil \\
%Jawa Tengah & 33 & Jateng & ID-JT & Jawa & Semarang & Ganjar Pranowo \\
%Daerah Istimewa Yogyakarta & 34 & DIY & ID-YO & Jawa & Yogyakarta & Hamengkubuwana X \\
%Jawa Timur & 35 & Jatim & ID-JI & Jawa & Surabaya & Khofifah Indar Parawansa \\
%Banten & 36 & Banten & ID-BT & Jawa & Serang & Al Muktabar \\
%Bali & 51 & Bali & ID-BA & Nusa Tenggara & Denpasar & I Wayan Koster \\
%Nusa Tenggara Barat & 52 & NTB & ID-NB & Nusa Tenggara & Mataram & Zulkieflimansyah \\
%Nusa Tenggara Timur & 53 & NTT & ID-NT & Nusa Tenggara & Kupang & Viktor Laiskodat \\

%Kalimantan Barat & 61 & Kalbar & ID-KB & Kalimantan & Pontianak & Sutarmidji \\
%Kalimantan Tengah & 62 & Kalteng & ID-KT & Kalimantan & Palangka Raya & Sugianto Sabran \\
%Kalimantan Selatan & 63 & Kalsel & ID-KS & Kalimantan & Banjarbaru & Sahbirin Noor \\
%Kalimantan Timur & 64 & Kaltim & ID-KI & Kalimantan & Samarinda & Isran Noor \\
%Kalimantan Utara & 65 & Kaltara & ID-KU & Kalimantan & Tanjung Selor & Zainal Arifin Paliwang \\
%Sulawesi Utara & 71 & Sulut & ID-SA & Sulawesi & Manado & Olly Dondokambey \\
%Sulawesi Tengah & 72 & Sulteng & ID-ST & Sulawesi & Palu & Rusdy Mastura \\
%Sulawesi Selatan & 73 & Sulsel & ID-SN & Sulawesi & Makassar & Andi Sudirman Sulaiman \\
%Sulawesi Tenggara & 74 & Sultra & ID-SG & Sulawesi & Kendari & Ali Mazi \\
%Gorontalo & 75 & Gorontalo & ID-GO & Sulawesi & Gorontalo & Hamka Hendra Noer \\
%Sulawesi Barat & 76 & Sulbar & ID-SR & Sulawesi & Mamuju & Akmal Malik \\
%Maluku & 81 & Maluku & ID-MA & Maluku & Ambon & Murad Ismail \\
%Maluku Utara & 82 & Malut & ID-MU & Maluku & Sofifi & Abdul Ghani Kasuba \\
%Papua & 91 & Papua & ID-PA & Papua & Jayapura & Lukas Enembe \\
%Papua Barat & 92 & Pabar & ID-PB & Papua & Manokwari & Paulus Waterpauw \\
%Papua Selatan & 93 & Pasel & — & Papua & Merauke & Apolo Safanpo \\
%Papua Tengah & 94 & Papteng & — & Papua & Nabire & Ribka Haluk \\
%Papua Pegunungan & 95 & Papeg & — & Papua & Wamena & Nikolaus Kondomo \\
%Papua Barat Daya & 96 & PBD & — & Papua & Sorong1 & — \\ \hline
%\label{table:tabelpanjanglebar}
%\end{longtable}
%\end{landscape}


%		\subsection{Subsubbab 2 2}
%		\blindtext

%	\section{Subab 3}
%	\blindtext \ref{fig:komputer}

%\begin{equation}
 %   x+2 = 159
%\end{equation}
%\blindtext

%Berikut adalah contoh gambar yang dicetak secara horizontal
%\begin{landscape}
 %  \begin{figure}[t]
  %      \centering
   %     \includegraphics[width=18cm, height=12cm]{gambar/contoh-gambar-miring.png}
    %    \caption{Contoh Gambar Komputer}
     %   \label{fig:komputer}
    %\end{figure}
%\end{landscape}

